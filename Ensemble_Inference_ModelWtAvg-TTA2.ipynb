{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import timm\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import albumentations\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from albumentations.core.composition import Compose\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from typing import Any, Dict, List, Union, Optional\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import cv2\n",
    "import torch\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "pytorch_lightning.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'C:\\Users\\Kaggle\\Leaf_Classification\\input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read csv and label mapping\n",
    "\n",
    "labels = pd.read_csv(os.path.join(base_dir,'train.csv'))\n",
    "\n",
    "with open(f'{base_dir}/label_num_to_disease_map.json') as f:\n",
    "    label_mapper = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_names: List,\n",
    "        transforms: Compose,\n",
    "        labels: Optional[List[int]],\n",
    "        img_path: str = '',\n",
    "        mode: str = 'train',\n",
    "        labels_to_ohe: bool = False,\n",
    "        n_classes: int = 5,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Image classification dataset.\n",
    "\n",
    "        Args:\n",
    "            df: dataframe with image id and bboxes\n",
    "            mode: train/val/test\n",
    "            img_path: path to images\n",
    "            transforms: albumentations\n",
    "        \"\"\"\n",
    "\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms\n",
    "        self.img_path = img_path\n",
    "        self.image_names = image_names\n",
    "        if labels is not None:\n",
    "            if not labels_to_ohe:\n",
    "                self.labels = np.array(labels)\n",
    "            else:\n",
    "                self.labels = np.zeros((len(labels), n_classes))\n",
    "                self.labels[np.arange(len(labels)), np.array(labels)] = 1\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, np.array]:\n",
    "        image_path = self.img_path + self.image_names[idx]\n",
    "        image = cv2.imread(f'{image_path}', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(image_path)\n",
    "        target = self.labels[idx]\n",
    "\n",
    "        img = self.transforms(image=image)['image']\n",
    "        sample = {'image_path': image_path, 'image': img, 'target': np.array(target).astype('int64')}\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 576\n",
    "sz_efffnetb4 = 600\n",
    "deit_size = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA0_deit = albumentations.Compose([\n",
    "#             albumentations.CenterCrop(600, 600,p=1),\n",
    "#             albumentations.Resize(deit_size,deit_size,cv2.INTER_AREA),\n",
    "#             albumentations.Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406], \n",
    "#                 std=[0.229, 0.224, 0.225], \n",
    "#                 max_pixel_value=255.0, \n",
    "#                 p=1.0\n",
    "#             ),\n",
    "#             ToTensorV2()],\n",
    "#             p=1.)\n",
    "\n",
    "\n",
    "# TTA1_deit = albumentations.Compose([\n",
    "#             albumentations.CenterCrop(600, 600,p=1),\n",
    "#             albumentations.Resize(deit_size,deit_size,cv2.INTER_AREA),\n",
    "#             albumentations.HorizontalFlip(p=1),\n",
    "#             albumentations.Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406], \n",
    "#                 std=[0.229, 0.224, 0.225], \n",
    "#                 max_pixel_value=255.0, \n",
    "#                 p=1.0\n",
    "#             ),\n",
    "#             ToTensorV2()],\n",
    "#             p=1.)\n",
    "\n",
    "\n",
    "# TTA2_deit = albumentations.Compose([\n",
    "#             albumentations.CenterCrop(600, 600,p=1),\n",
    "#             albumentations.Resize(deit_size,deit_size,cv2.INTER_AREA),\n",
    "#             albumentations.VerticalFlip(p=1),\n",
    "#             albumentations.Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406], \n",
    "#                 std=[0.229, 0.224, 0.225], \n",
    "#                 max_pixel_value=255.0, \n",
    "#                 p=1.0\n",
    "#             ),\n",
    "#             ToTensorV2()],\n",
    "#             p=1.)\n",
    "\n",
    "\n",
    "# TTA2_5_deit = albumentations.Compose([\n",
    "#             albumentations.CenterCrop(600, 600,p=1),\n",
    "#             albumentations.Resize(deit_size,deit_size,cv2.INTER_AREA),\n",
    "#             albumentations.Transpose(p=1.),\n",
    "#             albumentations.Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406], \n",
    "#                 std=[0.229, 0.224, 0.225], \n",
    "#                 max_pixel_value=255.0, \n",
    "#                 p=1.0\n",
    "#             ),\n",
    "#             ToTensorV2()],\n",
    "#             p=1.)\n",
    "\n",
    "# TTA3_deit = albumentations.Compose([\n",
    "#             albumentations.CenterCrop(600, 600,p=1),\n",
    "#             albumentations.Resize(deit_size,deit_size,cv2.INTER_AREA),\n",
    "#             albumentations.HueSaturationValue(\n",
    "#                 hue_shift_limit=0.2, \n",
    "#                 sat_shift_limit=0.2, \n",
    "#                 val_shift_limit=0.2, \n",
    "#                 p=1\n",
    "#             ),\n",
    "#            albumentations.Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406], \n",
    "#                 std=[0.229, 0.224, 0.225], \n",
    "#                 max_pixel_value=255.0, \n",
    "#                 p=1.0\n",
    "#             ),\n",
    "#             ToTensorV2()],\n",
    "#             p=1.)\n",
    "\n",
    "\n",
    "# TTA4_deit = albumentations.Compose([\n",
    "#             albumentations.CenterCrop(600, 600,p=1),\n",
    "#             albumentations.Resize(deit_size,deit_size,cv2.INTER_AREA),\n",
    "#             albumentations.RandomBrightnessContrast(\n",
    "#                 brightness_limit=(-0.1,0.1), \n",
    "#                 contrast_limit=(-0.1, 0.1), \n",
    "#                 p=1.\n",
    "#             ),\n",
    "#             albumentations.Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406], \n",
    "#                 std=[0.229, 0.224, 0.225], \n",
    "#                 max_pixel_value=255.0, \n",
    "#                 p=1.0\n",
    "#             ),\n",
    "#             ToTensorV2()],\n",
    "#             p=1.)\n",
    "\n",
    "\n",
    "# TTA5_deit = albumentations.Compose([\n",
    "#             albumentations.CenterCrop(600, 600,p=1),\n",
    "#             albumentations.Resize(deit_size,deit_size,cv2.INTER_AREA),\n",
    "#             albumentations.Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406], \n",
    "#                 std=[0.229, 0.224, 0.225], \n",
    "#                 max_pixel_value=255.0, \n",
    "#                 p=1.0\n",
    "#             ),\n",
    "#             albumentations.Cutout(p=1.), \n",
    "#             ToTensorV2()],\n",
    "#             p=1.)\n",
    "\n",
    "# TTA6_deit = albumentations.Compose([\n",
    "#             albumentations.CenterCrop(600, 600,p=1),\n",
    "#             albumentations.Resize(deit_size,deit_size,cv2.INTER_AREA),\n",
    "#             albumentations.ShiftScaleRotate(p=1.),\n",
    "#             albumentations.Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406], \n",
    "#                 std=[0.229, 0.224, 0.225], \n",
    "#                 max_pixel_value=255.0, \n",
    "#                 p=1.0\n",
    "#             ),\n",
    "#             ToTensorV2()],\n",
    "#             p=1.)\n",
    "\n",
    "# TTA7_deit = albumentations.Compose([\n",
    "#             albumentations.CenterCrop(600, 600,p=1),\n",
    "#             albumentations.Resize(deit_size,deit_size,cv2.INTER_AREA),\n",
    "#             albumentations.Normalize(\n",
    "#                 mean=[0.485, 0.456, 0.406], \n",
    "#                 std=[0.229, 0.224, 0.225], \n",
    "#                 max_pixel_value=255.0, \n",
    "#                 p=1.0\n",
    "#             ),\n",
    "#             albumentations.CoarseDropout(p=1.),\n",
    "#             ToTensorV2()],\n",
    "#             p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA0_deit = albumentations.Compose([\n",
    "            albumentations.Resize(deit_size, deit_size,p=1),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "\n",
    "TTA1_deit = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(deit_size, deit_size),\n",
    "            albumentations.HorizontalFlip(p=1),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "\n",
    "TTA2_deit = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(deit_size, deit_size),\n",
    "            albumentations.VerticalFlip(p=1),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "\n",
    "TTA2_5_deit = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(deit_size, deit_size),\n",
    "            albumentations.Transpose(p=1.),\n",
    "           albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "TTA3_deit = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(deit_size, deit_size),\n",
    "            albumentations.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=1\n",
    "            ),\n",
    "           albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "\n",
    "TTA4_deit = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(deit_size, deit_size),\n",
    "            albumentations.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=1.\n",
    "            ),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "\n",
    "TTA5_deit = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(deit_size, deit_size),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            albumentations.Cutout(p=1.), \n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "TTA6_deit = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(deit_size, deit_size),\n",
    "            albumentations.ShiftScaleRotate(p=1.),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "TTA7_deit = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(deit_size, deit_size),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            albumentations.CoarseDropout(p=1.),\n",
    "            ToTensorV2()],\n",
    "            p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA0 = albumentations.Compose([\n",
    "            albumentations.Resize(sz, sz,p=1),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "\n",
    "TTA1 = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(sz, sz),\n",
    "            albumentations.HorizontalFlip(p=1),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "\n",
    "TTA2 = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(sz, sz),\n",
    "            albumentations.VerticalFlip(p=1),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "\n",
    "TTA2_5 = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(sz, sz),\n",
    "            albumentations.Transpose(p=1.),\n",
    "           albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "TTA3 = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(sz, sz),\n",
    "            albumentations.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=1\n",
    "            ),\n",
    "           albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "\n",
    "TTA4 = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(sz, sz),\n",
    "            albumentations.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=1.\n",
    "            ),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "\n",
    "TTA5 = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(sz, sz),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            albumentations.Cutout(p=1.), \n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "TTA6 = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(sz, sz),\n",
    "            albumentations.ShiftScaleRotate(p=1.),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "TTA7 = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(sz, sz),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            albumentations.CoarseDropout(p=1.),\n",
    "            ToTensorV2()],\n",
    "            p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_augs_effnet = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(sz_efffnetb4, sz_efffnetb4),\n",
    "            albumentations.Transpose(p=0.5),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.ShiftScaleRotate(p=0.5),\n",
    "            albumentations.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "            albumentations.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            albumentations.CoarseDropout(p=0.5),\n",
    "            albumentations.Cutout(p=0.5), \n",
    "            ToTensorV2()],\n",
    "            p=1.)\n",
    "\n",
    "\n",
    "infer_augs_resnext = albumentations.Compose([\n",
    "            albumentations.RandomResizedCrop(sz, sz),\n",
    "            albumentations.Transpose(p=0.5),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.ShiftScaleRotate(p=0.5),\n",
    "            albumentations.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "            albumentations.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            albumentations.CoarseDropout(p=0.5),\n",
    "            albumentations.Cutout(p=0.5), \n",
    "            ToTensorV2()],\n",
    "            p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PL module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_until(net: Any, param_name: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Freeze net until param_name\n",
    "\n",
    "\n",
    "    Args:\n",
    "        net:\n",
    "        param_name:\n",
    "\n",
    "    \"\"\"\n",
    "    found_name = False\n",
    "    for name, params in net.named_parameters():\n",
    "        if name == param_name:\n",
    "            found_name = True\n",
    "        params.requires_grad = found_name\n",
    "\n",
    "class BasicEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        arch: str = 'resnet18',\n",
    "        source: str = 'torchvision',\n",
    "        pretrained: str = None,\n",
    "        n_layers: int = -1,\n",
    "        freeze: bool = False,\n",
    "        to_one_channel: bool = False,\n",
    "        freeze_until_layer: str = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize Encoder.\n",
    "\n",
    "        Args:\n",
    "            num_classes: the number of target classes, the size of the last layer's output\n",
    "            arch: the name of the architecture form pretrainedmodels\n",
    "            pretrained: the mode for pretrained model from pretrainedmodels\n",
    "            n_layers: number of layers to keep\n",
    "            freeze: to freeze model\n",
    "            freeze_until: freeze until this layer. If None, then freeze all layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if source == 'timm':\n",
    "            net = timm.create_model(arch, pretrained=pretrained)\n",
    "            self.output_dimension = list(net.children())[-1].in_features\n",
    "        else:\n",
    "            print(\"Not implemented\")\n",
    "            \n",
    "        if freeze:\n",
    "            freeze_until(net, freeze_until_layer)\n",
    "        \n",
    "        layers = list(net.children())[:n_layers]    \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.layers(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDecoder(nn.Module):\n",
    "    def __init__(self, pool_output_size: int = 1, n_classes: int = 5, output_dimension: int = 512) -> None:\n",
    "        \"\"\"\n",
    "        Initialize Decoder.\n",
    "\n",
    "        Args:\n",
    "            pool_output_size: the size of the result feature map after adaptive pooling layer\n",
    "            n_classes: n classes to output\n",
    "            output_dimension: output dimension of encoder\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #self.pool = nn.AdaptiveAvgPool2d(output_size=pool_output_size)\n",
    "        self.fc = nn.Linear(output_dimension , n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.pool(x)\n",
    "        output = self.fc(x.view(x.size()[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDecoder_newhead(nn.Module):\n",
    "    def __init__(self, pool_output_size: int = 1, n_classes: int = 5, output_dimension: int = 512) -> None:\n",
    "        \"\"\"\n",
    "        Initialize Decoder.\n",
    "\n",
    "        Args:\n",
    "            pool_output_size: the size of the result feature map after adaptive pooling layer\n",
    "            n_classes: n classes to output\n",
    "            output_dimension: output dimension of encoder\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #self.pool = nn.AdaptiveAvgPool2d(output_size=pool_output_size)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(output_dimension, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 5),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.pool(x)\n",
    "        output = self.fc(x.view(x.size()[0], -1))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_B4_newhead(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Model class.\n",
    "\n",
    "        Args:\n",
    "            cfg: main config\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = BasicEncoder(arch='tf_efficientnet_b4_ns',\n",
    "                                    source='timm',\n",
    "                                    pretrained=False,\n",
    "                                    n_layers=-1,\n",
    "                                    freeze=False,\n",
    "                                    to_one_channel=False,\n",
    "                                    freeze_until_layer=None)\n",
    "        self.decoder = BasicDecoder_newhead(1,5,self.encoder.output_dimension)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out = self.encoder(x)\n",
    "        logits = self.decoder(out)\n",
    "        loss = self.loss(logits, targets).view(1)\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_B3(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Model class.\n",
    "\n",
    "        Args:\n",
    "            cfg: main config\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = BasicEncoder(arch='tf_efficientnet_b3_ns',\n",
    "                                    source='timm',\n",
    "                                    pretrained=False,\n",
    "                                    n_layers=-1,\n",
    "                                    freeze=False,\n",
    "                                    to_one_channel=False,\n",
    "                                    freeze_until_layer=None)\n",
    "        self.decoder = BasicDecoder_newhead(1,5,self.encoder.output_dimension)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out = self.encoder(x)\n",
    "        logits = self.decoder(out)\n",
    "        loss = self.loss(logits, targets).view(1)\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_B4(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Model class.\n",
    "\n",
    "        Args:\n",
    "            cfg: main config\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = BasicEncoder(arch='tf_efficientnet_b4_ns',\n",
    "                                    source='timm',\n",
    "                                    pretrained=False,\n",
    "                                    n_layers=-1,\n",
    "                                    freeze=False,\n",
    "                                    to_one_channel=False,\n",
    "                                    freeze_until_layer=None)\n",
    "        self.decoder = BasicDecoder(1,5,self.encoder.output_dimension)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out = self.encoder(x)\n",
    "        logits = self.decoder(out)\n",
    "        loss = self.loss(logits, targets).view(1)\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_B5(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Model class.\n",
    "\n",
    "        Args:\n",
    "            cfg: main config\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = BasicEncoder(arch='tf_efficientnet_b5_ns',\n",
    "                                    source='timm',\n",
    "                                    pretrained=False,\n",
    "                                    n_layers=-1,\n",
    "                                    freeze=False,\n",
    "                                    to_one_channel=False,\n",
    "                                    freeze_until_layer=None)\n",
    "        self.decoder = BasicDecoder(1,5,self.encoder.output_dimension)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out = self.encoder(x)\n",
    "        logits = self.decoder(out)\n",
    "        loss = self.loss(logits, targets).view(1)\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDecoder_seresnext(nn.Module):\n",
    "    def __init__(self, pool_output_size: int = 1, n_classes: int = 5, output_dimension: int = 512) -> None:\n",
    "        \"\"\"\n",
    "        Initialize Decoder.\n",
    "\n",
    "        Args:\n",
    "            pool_output_size: the size of the result feature map after adaptive pooling layer\n",
    "            n_classes: n classes to output\n",
    "            output_dimension: output dimension of encoder\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #self.pool = nn.AdaptiveAvgPool2d(output_size=pool_output_size)\n",
    "        #self.fc = nn.Linear(output_dimension , n_classes)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(output_dimension, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 5),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        #x = self.pool(x)\n",
    "        output = self.fc(x.view(x.size()[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seResnextNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Model class.\n",
    "\n",
    "        Args:\n",
    "            cfg: main config\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = BasicEncoder(arch='seresnext50_32x4d',\n",
    "                                    source='timm',\n",
    "                                    pretrained=False,\n",
    "                                    n_layers=-1,\n",
    "                                    freeze=False,\n",
    "                                    to_one_channel=False,\n",
    "                                    freeze_until_layer=None)\n",
    "        self.decoder = BasicDecoder_seresnext(1,5,self.encoder.output_dimension)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out = self.encoder(x)\n",
    "        logits = self.decoder(out)\n",
    "        loss = self.loss(logits, targets).view(1)\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnextNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Model class.\n",
    "\n",
    "        Args:\n",
    "            cfg: main config\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = BasicEncoder(arch='resnext50_32x4d',\n",
    "                                    source='timm',\n",
    "                                    pretrained=False,\n",
    "                                    n_layers=-1,\n",
    "                                    freeze=False,\n",
    "                                    to_one_channel=False,\n",
    "                                    freeze_until_layer=None)\n",
    "        self.decoder = BasicDecoder(1,5,self.encoder.output_dimension)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out = self.encoder(x)\n",
    "        logits = self.decoder(out)\n",
    "        loss = self.loss(logits, targets).view(1)\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnextNet50d(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Model class.\n",
    "\n",
    "        Args:\n",
    "            cfg: main config\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = BasicEncoder(arch='resnext50d_32x4d',\n",
    "                                    source='timm',\n",
    "                                    pretrained=False,\n",
    "                                    n_layers=-1,\n",
    "                                    freeze=False,\n",
    "                                    to_one_channel=False,\n",
    "                                    freeze_until_layer=None)\n",
    "        self.decoder = BasicDecoder_newhead(1,5,self.encoder.output_dimension)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out = self.encoder(x)\n",
    "        logits = self.decoder(out)\n",
    "        loss = self.loss(logits, targets).view(1)\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnest50d(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Model class.\n",
    "\n",
    "        Args:\n",
    "            cfg: main config\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = BasicEncoder(arch='resnest50d_1s4x24d',\n",
    "                                    source='timm',\n",
    "                                    pretrained=False,\n",
    "                                    n_layers=-1,\n",
    "                                    freeze=False,\n",
    "                                    to_one_channel=False,\n",
    "                                    freeze_until_layer=None)\n",
    "        self.decoder = BasicDecoder_newhead(1,5,self.encoder.output_dimension)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out = self.encoder(x)\n",
    "        logits = self.decoder(out)\n",
    "        loss = self.loss(logits, targets).view(1)\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DEIT(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "        Model class.\n",
    "\n",
    "        Args:\n",
    "            cfg: main config\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_384', pretrained=True)\n",
    "        output_dimension = list(self.encoder.children())[-1].in_features\n",
    "\n",
    "        self.encoder.head = nn.Sequential(\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 5),\n",
    "        )\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    def forward(self, x, targets):\n",
    "        logits = self.encoder(x)\n",
    "        loss = self.loss(logits, targets).view(1)\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCassava(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super(LitCassava, self).__init__()\n",
    "        self.model = model\n",
    "        self.metric = pl.metrics.Accuracy()\n",
    "        self.learning_rate = 1e-4\n",
    "\n",
    "    def forward(self, x, targets, *args, **kwargs):\n",
    "        return self.model(x, targets)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.learning_rate, weight_decay=0.001)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=2)\n",
    "\n",
    "        return (\n",
    "            [optimizer],\n",
    "            [{'scheduler': scheduler, 'interval': 'epoch', 'monitor': 'valid_loss'}],\n",
    "        )\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: torch.Tensor, batch_idx: int\n",
    "    ) -> Union[int, Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]]:\n",
    "        image = batch['image']\n",
    "        target = batch['target']\n",
    "        logits, loss = self(image, target)\n",
    "        score = self.metric(logits.argmax(1), target)\n",
    "        logs = {'train_loss': loss, f'train_accuracy': score}\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'log': logs,\n",
    "            'progress_bar': logs,\n",
    "            'logits': logits,\n",
    "            'target': target,\n",
    "            f'train_accuracy': score,\n",
    "        }\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        y_true = torch.cat([x['target'] for x in outputs])\n",
    "        y_pred = torch.cat([x['logits'] for x in outputs])\n",
    "        score = self.metric(y_pred.argmax(1), y_true)\n",
    "        \n",
    "        logs = {'train_loss': avg_loss, 'train_accuracy': score}\n",
    "        return {'log': logs, 'progress_bar': logs}\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: torch.Tensor, batch_idx: int\n",
    "    ) -> Union[int, Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]]:\n",
    "        image = batch['image']\n",
    "        target = batch['target']\n",
    "        logits, loss = self(image, target)\n",
    "        score = self.metric(logits.argmax(1), target)\n",
    "        logs = {'valid_loss': loss, f'valid_accuracy': score}\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'log': logs,\n",
    "            'progress_bar': logs,\n",
    "            'logits': logits,\n",
    "            'target': target,\n",
    "            f'valid_accuracy': score,\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        y_true = torch.cat([x['target'] for x in outputs])\n",
    "        y_pred = torch.cat([x['logits'] for x in outputs])\n",
    "        score = self.metric(y_pred.argmax(1), y_true)\n",
    "\n",
    "        # score = torch.tensor(1.0, device=self.device)\n",
    "        logs = {'valid_loss': avg_loss, f'valid_accuracy': score, 'accuracy': score}\n",
    "        return {'valid_loss': avg_loss, 'log': logs, 'progress_bar': logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"../input/cassava-leaf-disease-classification/\"\n",
    "# sub = pd.read_csv(f'{path}/sample_submission.csv')\n",
    "# sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getloader(df,path,bs=8,fold=0,tta=0,deit=False):\n",
    "    \n",
    "    if not deit:\n",
    "        if tta == 0:\n",
    "            augs = TTA0\n",
    "        if tta == 1:\n",
    "            augs = TTA1\n",
    "        if tta == 2:\n",
    "            augs = TTA2\n",
    "        if tta == 3:\n",
    "            augs = TTA2_5\n",
    "        if tta == 4:\n",
    "            augs = TTA3\n",
    "        if tta == 5:\n",
    "            augs = TTA4\n",
    "        if tta == 6:\n",
    "            augs = TTA5\n",
    "        if tta == 7:\n",
    "            augs = TTA6\n",
    "        if tta == 8:\n",
    "            augs = TTA7\n",
    "    else:\n",
    "        if tta == 0:\n",
    "            augs = TTA0_deit\n",
    "        if tta == 1:\n",
    "            augs = TTA1_deit\n",
    "        if tta == 2:\n",
    "            augs = TTA2_deit\n",
    "        if tta == 3:\n",
    "            augs = TTA2_5_deit\n",
    "        if tta == 4:\n",
    "            augs = TTA3_deit\n",
    "        if tta == 5:\n",
    "            augs = TTA4_deit\n",
    "        if tta == 6:\n",
    "            augs = TTA5_deit\n",
    "        if tta == 7:\n",
    "            augs = TTA6_deit\n",
    "        if tta == 8:\n",
    "            augs = TTA7_deit\n",
    "    \n",
    "    print(f\"Using TTA: {tta} and DEIT:{deit}\")\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    train_indexes, valid_indexes = list(folds.split(df, df['label']))[fold]\n",
    "\n",
    "    train_df = df.iloc[train_indexes]\n",
    "    valid_df = df.iloc[valid_indexes]\n",
    "\n",
    "\n",
    "    train_dataset = ImageClassificationDataset(image_names=train_df['image_id'].values,\n",
    "                                                    transforms=augs,\n",
    "                                                    labels=train_df['label'].values,\n",
    "                                                    img_path=path,\n",
    "                                                    mode='train',\n",
    "                                                    labels_to_ohe=False,\n",
    "                                                    n_classes=5)\n",
    "    valid_dataset = ImageClassificationDataset(image_names=valid_df['image_id'].values,\n",
    "                                                    transforms=augs,\n",
    "                                                    labels=valid_df['label'].values,\n",
    "                                                    img_path=path,\n",
    "                                                    mode='valid',\n",
    "                                                    labels_to_ohe=False,\n",
    "                                                    n_classes=5)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=bs,num_workers=0,shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=bs,num_workers=0,shuffle=False)\n",
    "\n",
    "    return train_loader,valid_loader,valid_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = os.listdir('../input/leaves-tf-enet-b4-ns-576-finetune-temperedloss/')\n",
    "# modelsPath = [os.path.join('../input/leaves-tf-enet-b4-ns-576-finetune-temperedloss',i) for i in models]\n",
    "# modelsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def getPreds(test_loader,lit_model,logitsOut=True):\n",
    "    predictions = []\n",
    "    \n",
    "    for batch in tqdm(test_loader):\n",
    "        image = batch['image'].to('cuda')\n",
    "        target = batch['target'].to('cuda')\n",
    "        with torch.no_grad():\n",
    "            outputs = lit_model.model(image, target)[0]\n",
    "            _outputs = outputs.softmax(1).detach().cpu().numpy()\n",
    "            preds = outputs.argmax(1).detach().cpu().numpy()\n",
    "            if not logitsOut:\n",
    "                predictions.append(preds)\n",
    "            else:\n",
    "                #predictions[range(len(_outputs))] += _outputs\n",
    "                predictions.append(_outputs)\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preds for DEIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsPath = {0:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\DEIT_Mixup_without_hesitation_After_Epoch10\\avgWeights\\_Avg_fold_0.ckpt',\n",
    "              1:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\DEIT_Mixup_without_hesitation_After_Epoch10\\avgWeights\\_Avg_fold_1.ckpt',\n",
    "              2:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\DEIT_Mixup_without_hesitation_After_Epoch10\\avgWeights\\_Avg_fold_2.ckpt',\n",
    "              3:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\DEIT_Mixup_without_hesitation_After_Epoch10\\avgWeights\\_Avg_fold_3.ckpt',\n",
    "              4:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\DEIT_Mixup_without_hesitation_After_Epoch10\\avgWeights\\_Avg_fold_4.ckpt'}\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Rajneesh Tiwari/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:10<00:00,  1.90it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:06<00:00,  2.01it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "Using cache found in C:\\Users\\Rajneesh Tiwari/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:06<00:00,  2.02it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:06<00:00,  2.02it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "Using cache found in C:\\Users\\Rajneesh Tiwari/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:06<00:00,  2.01it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:06<00:00,  2.02it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "Using cache found in C:\\Users\\Rajneesh Tiwari/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:06<00:00,  2.01it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:06<00:00,  2.01it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "Using cache found in C:\\Users\\Rajneesh Tiwari/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:06<00:00,  2.02it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:06<00:00,  2.02it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "preds_DEIT = np.zeros((len(labels),5))\n",
    "\n",
    "train_img_path = 'C:/Users/Kaggle/Leaf_Classification/input/train_images/'\n",
    "TTA = TTA\n",
    "for f in range(5):    \n",
    "    softmaxOut = 0.\n",
    "    print(f\"Prediction for fold:{f}\")\n",
    "    modelPath = modelsPath[f]\n",
    "    model = DEIT()\n",
    "    lit_model = LitCassava(model)\n",
    "    checkpoint = torch.load(modelPath, map_location=lambda storage, loc: storage)\n",
    "    lit_model.load_state_dict(checkpoint)      \n",
    "#    lit_model.load_state_dict(checkpoint['state_dict'])  \n",
    "    lit_model.model.eval()\n",
    "    lit_model.model.cuda()\n",
    "    for tta in range(TTA):\n",
    "        _,test_loader,valid_ix = getloader(labels,path=train_img_path,bs=32,fold=f,tta=tta,deit=True)\n",
    "        predictions = []\n",
    "        softmaxOut+= (getPreds(test_loader,lit_model,logitsOut=True))\n",
    "    preds_DEIT[valid_ix,:] = np.vstack(softmaxOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean_DEIT = preds_DEIT.copy()\n",
    "preds_mean_DEIT[:,0]= preds_DEIT[:,0]/(1+np.sqrt(0.05))\n",
    "preds_mean_DEIT[:,1]= preds_DEIT[:,1]/(1+np.sqrt(0.102))\n",
    "preds_mean_DEIT[:,2]= preds_DEIT[:,2]/(1+np.sqrt(0.111))\n",
    "preds_mean_DEIT[:,3]= preds_DEIT[:,3]/(1+np.sqrt(0.614)) #### not the exact frequency stats here, instead of 0.614, we have used 0.4 \n",
    "preds_mean_DEIT[:,4]= preds_DEIT[:,4]/(1+np.sqrt(0.12))\n",
    "\n",
    "classOut = np.argmax(preds_mean_DEIT,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8920876758424078, 0.893396270505211)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels.label,classOut),accuracy_score(labels.label,np.argmax(preds_DEIT,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del _,softmaxOut,model,lit_model,checkpoint,test_loader; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preds for effnet B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelsDir = os.listdir(r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\seresnext50_32x4d_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\'')\n",
    "\n",
    "modelsPath = {0:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b3_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\avgWeights\\_Avg_fold_0.ckpt',\n",
    "              1:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b3_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\avgWeights\\_Avg_fold_1.ckpt',\n",
    "              2:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b3_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\avgWeights\\_Avg_fold_2.ckpt',\n",
    "              3:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b3_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\avgWeights\\_Avg_fold_3.ckpt',\n",
    "              4:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b3_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\avgWeights\\_Avg_fold_4.ckpt'}\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelsDir = os.listdir(r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\seresnext50_32x4d_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\)\n",
    "\n",
    "# modelsPath = [os.path.join(r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\seresnext50_32x4d_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\best_ones',i) for i in models]\n",
    "# modelsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:16<00:00,  1.76it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:16<00:00,  1.76it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:15<00:00,  1.76it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:16<00:00,  1.76it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:15<00:00,  1.77it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:16<00:00,  1.75it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:15<00:00,  1.76it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:16<00:00,  1.75it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:15<00:00,  1.76it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:16<00:00,  1.75it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "preds_effnet_b3 = np.zeros((len(labels),5))\n",
    "\n",
    "train_img_path = 'C:/Users/Kaggle/Leaf_Classification/input/train_images/'\n",
    "TTA = TTA\n",
    "for f in range(5):    \n",
    "    softmaxOut = 0.\n",
    "    print(f\"Prediction for fold:{f}\")\n",
    "    modelPath = modelsPath[f]\n",
    "    model = Net_B3()\n",
    "    lit_model = LitCassava(model)\n",
    "    checkpoint = torch.load(modelPath, map_location=lambda storage, loc: storage)\n",
    "    lit_model.load_state_dict(checkpoint)      \n",
    "#    lit_model.load_state_dict(checkpoint['state_dict'])  \n",
    "    lit_model.model.eval()\n",
    "    lit_model.model.cuda()\n",
    "    for tta in range(TTA):\n",
    "        _,test_loader,valid_ix = getloader(labels,path=train_img_path,bs=32,fold=f,tta=tta)\n",
    "        predictions = []\n",
    "        softmaxOut+= (getPreds(test_loader,lit_model,logitsOut=True))\n",
    "    preds_effnet_b3[valid_ix,:] = np.vstack(softmaxOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean_effnetb3 = preds_effnet_b3.copy()\n",
    "preds_mean_effnetb3[:,0]= preds_effnet_b3[:,0]/(1+np.sqrt(0.05))\n",
    "preds_mean_effnetb3[:,1]= preds_effnet_b3[:,1]/(1+np.sqrt(0.102))\n",
    "preds_mean_effnetb3[:,2]= preds_effnet_b3[:,2]/(1+np.sqrt(0.111))\n",
    "preds_mean_effnetb3[:,3]= preds_effnet_b3[:,3]/(1+np.sqrt(0.614)) #### not the exact frequency stats here, instead of 0.614, we have used 0.4 \n",
    "preds_mean_effnetb3[:,4]= preds_effnet_b3[:,4]/(1+np.sqrt(0.12))\n",
    "\n",
    "classOut = np.argmax(preds_mean_effnetb3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8902649904192177, 0.8952656914520727)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels.label,classOut),accuracy_score(labels.label,np.argmax(preds_effnet_b3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del _,softmaxOut,model,lit_model,checkpoint,test_loader; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preds for seresnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelsDir = os.listdir(r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\seresnext50_32x4d_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\'')\n",
    "\n",
    "modelsPath = {0:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\seresnext50_32x4d_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\avgWeights\\_Avg_fold_0.ckpt',\n",
    "              1:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\seresnext50_32x4d_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\avgWeights\\_Avg_fold_1.ckpt',\n",
    "              2:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\seresnext50_32x4d_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\avgWeights\\_Avg_fold_2.ckpt',\n",
    "              3:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\seresnext50_32x4d_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\avgWeights\\_Avg_fold_3.ckpt',\n",
    "              4:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\seresnext50_32x4d_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\avgWeights\\_Avg_fold_4.ckpt'\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelsDir = os.listdir(r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\seresnext50_32x4d_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\)\n",
    "\n",
    "# modelsPath = [os.path.join(r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\seresnext50_32x4d_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\best_ones',i) for i in models]\n",
    "# modelsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 34/34 [01:40<00:00,  2.96s/it]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 34/34 [01:40<00:00,  2.96s/it]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 34/34 [01:40<00:00,  2.95s/it]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 34/34 [01:40<00:00,  2.96s/it]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 34/34 [01:40<00:00,  2.95s/it]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 34/34 [01:40<00:00,  2.96s/it]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 34/34 [01:40<00:00,  2.95s/it]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 34/34 [01:40<00:00,  2.96s/it]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 34/34 [01:40<00:00,  2.95s/it]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 34/34 [01:40<00:00,  2.96s/it]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "preds_seresnext = np.zeros((len(labels),5))\n",
    "\n",
    "train_img_path = 'C:/Users/Kaggle/Leaf_Classification/input/train_images/'\n",
    "TTA = TTA\n",
    "\n",
    "for f in range(5):\n",
    "    softmaxOut = 0.\n",
    "    print(f\"Prediction for fold:{f}\")\n",
    "    modelPath = modelsPath[f]\n",
    "    model = seResnextNet()\n",
    "    lit_model = LitCassava(model)\n",
    "    checkpoint = torch.load(modelPath, map_location=lambda storage, loc: storage)\n",
    "    lit_model.load_state_dict(checkpoint)  \n",
    "    lit_model.model.eval()\n",
    "    lit_model.model.cuda()\n",
    "    for tta in range(TTA):\n",
    "        _,test_loader,valid_ix = getloader(labels,path=train_img_path,bs=128,fold=f,tta=tta)\n",
    "        predictions = []\n",
    "        softmaxOut+= (getPreds(test_loader,lit_model,logitsOut=True))\n",
    "    preds_seresnext[valid_ix,:] = np.vstack(softmaxOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean_seresnext = preds_seresnext.copy()\n",
    "preds_mean_seresnext[:,0]= preds_mean_seresnext[:,0]/(1+np.sqrt(0.05))\n",
    "preds_mean_seresnext[:,1]= preds_mean_seresnext[:,1]/(1+np.sqrt(0.102))\n",
    "preds_mean_seresnext[:,2]= preds_mean_seresnext[:,2]/(1+np.sqrt(0.111))\n",
    "preds_mean_seresnext[:,3]= preds_mean_seresnext[:,3]/(1+np.sqrt(0.614)) #### not the exact frequency stats here, instead of 0.614, we have used 0.4 \n",
    "preds_mean_seresnext[:,4]= preds_mean_seresnext[:,4]/(1+np.sqrt(0.12))\n",
    "\n",
    "classOut = np.argmax(preds_mean_seresnext,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classOut = np.argmax(preds_seresnext,1)\n",
    "# classOut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.894517923073328, 0.8954058980230873)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels.label,classOut),accuracy_score(labels.label,np.argmax(preds_seresnext,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del _,softmaxOut,model,lit_model,checkpoint,test_loader; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preds for Effnet b4 Taylor Loss - 2 SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsPath = {0:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\Top 2\\avgWeights\\_Avg_fold_0.ckpt',\n",
    "              1:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\Top 2\\avgWeights\\_Avg_fold_1.ckpt',\n",
    "              2:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\Top 2\\avgWeights\\_Avg_fold_2.ckpt',\n",
    "              3:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\Top 2\\avgWeights\\_Avg_fold_3.ckpt',\n",
    "              4:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\Top 2\\avgWeights\\_Avg_fold_4.ckpt'\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:22<00:00,  1.62it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:22<00:00,  1.62it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:22<00:00,  1.62it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.60it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:22<00:00,  1.62it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "preds_effnet_b4_taylor = np.zeros((len(labels),5))\n",
    "\n",
    "train_img_path = 'C:/Users/Kaggle/Leaf_Classification/input/train_images/'\n",
    "TTA = TTA\n",
    "for f in range(5):    \n",
    "    softmaxOut = 0.\n",
    "    print(f\"Prediction for fold:{f}\")\n",
    "    modelPath = modelsPath[f]\n",
    "    model = Net_B4_newhead()\n",
    "    lit_model = LitCassava(model)\n",
    "    checkpoint = torch.load(modelPath, map_location=lambda storage, loc: storage)\n",
    "    lit_model.load_state_dict(checkpoint)      \n",
    "#    lit_model.load_state_dict(checkpoint['state_dict'])  \n",
    "    lit_model.model.eval()\n",
    "    lit_model.model.cuda()\n",
    "    for tta in range(TTA):\n",
    "        _,test_loader,valid_ix = getloader(labels,path=train_img_path,bs=32,fold=f,tta=tta)\n",
    "        predictions = []\n",
    "        softmaxOut+= (getPreds(test_loader,lit_model,logitsOut=True))\n",
    "    preds_effnet_b4_taylor[valid_ix,:] = np.vstack(softmaxOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean_effnetb4_taylor = preds_effnet_b4_taylor.copy()\n",
    "preds_mean_effnetb4_taylor[:,0]= preds_effnet_b4_taylor[:,0]/(1+np.sqrt(0.05))\n",
    "preds_mean_effnetb4_taylor[:,1]= preds_effnet_b4_taylor[:,1]/(1+np.sqrt(0.102))\n",
    "preds_mean_effnetb4_taylor[:,2]= preds_effnet_b4_taylor[:,2]/(1+np.sqrt(0.111))\n",
    "preds_mean_effnetb4_taylor[:,3]= preds_effnet_b4_taylor[:,3]/(1+np.sqrt(0.614)) #### not the exact frequency stats here, instead of 0.614, we have used 0.4 \n",
    "preds_mean_effnetb4_taylor[:,4]= preds_effnet_b4_taylor[:,4]/(1+np.sqrt(0.12))\n",
    "\n",
    "classOut = np.argmax(preds_mean_effnetb4_taylor,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8940505678366126, 0.8963873440201897)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels.label,classOut),accuracy_score(labels.label,np.argmax(preds_effnet_b4_taylor,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "del _,softmaxOut,model,lit_model,checkpoint,test_loader; gc.collect();torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preds for Effnet b4 Taylor Loss - 3 SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsPath = {0:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\avgWeights\\_Avg_fold_0.ckpt',\n",
    "              1:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\avgWeights\\_Avg_fold_1.ckpt',\n",
    "              2:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\avgWeights\\_Avg_fold_2.ckpt',\n",
    "              3:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\avgWeights\\_Avg_fold_3.ckpt',\n",
    "              4:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\avgWeights\\_Avg_fold_4.ckpt'\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:22<00:00,  1.62it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:24<00:00,  1.58it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.60it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:25<00:00,  1.57it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:24<00:00,  1.58it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:26<00:00,  1.54it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.60it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "preds_effnet_b4_taylor_3SWA = np.zeros((len(labels),5))\n",
    "\n",
    "train_img_path = 'C:/Users/Kaggle/Leaf_Classification/input/train_images/'\n",
    "TTA = TTA\n",
    "for f in range(5):    \n",
    "    softmaxOut = 0.\n",
    "    print(f\"Prediction for fold:{f}\")\n",
    "    modelPath = modelsPath[f]\n",
    "    model = Net_B4_newhead()\n",
    "    lit_model = LitCassava(model)\n",
    "    checkpoint = torch.load(modelPath, map_location=lambda storage, loc: storage)\n",
    "    lit_model.load_state_dict(checkpoint)      \n",
    "#    lit_model.load_state_dict(checkpoint['state_dict'])  \n",
    "    lit_model.model.eval()\n",
    "    lit_model.model.cuda()\n",
    "    for tta in range(TTA):\n",
    "        _,test_loader,valid_ix = getloader(labels,path=train_img_path,bs=32,fold=f,tta=tta)\n",
    "        predictions = []\n",
    "        softmaxOut+= (getPreds(test_loader,lit_model,logitsOut=True))\n",
    "    preds_effnet_b4_taylor_3SWA[valid_ix,:] = np.vstack(softmaxOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean_effnetb4_taylor_3SWA = preds_effnet_b4_taylor_3SWA.copy()\n",
    "preds_mean_effnetb4_taylor_3SWA[:,0]= preds_effnet_b4_taylor_3SWA[:,0]/(1+np.sqrt(0.05))\n",
    "preds_mean_effnetb4_taylor_3SWA[:,1]= preds_effnet_b4_taylor_3SWA[:,1]/(1+np.sqrt(0.102))\n",
    "preds_mean_effnetb4_taylor_3SWA[:,2]= preds_effnet_b4_taylor_3SWA[:,2]/(1+np.sqrt(0.111))\n",
    "preds_mean_effnetb4_taylor_3SWA[:,3]= preds_effnet_b4_taylor_3SWA[:,3]/(1+np.sqrt(0.614)) #### not the exact frequency stats here, instead of 0.614, we have used 0.4 \n",
    "preds_mean_effnetb4_taylor_3SWA[:,4]= preds_effnet_b4_taylor_3SWA[:,4]/(1+np.sqrt(0.12))\n",
    "\n",
    "classOut = np.argmax(preds_mean_effnetb4_taylor_3SWA,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8947048651680142, 0.8955928401177735)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels.label,classOut),accuracy_score(labels.label,np.argmax(preds_effnet_b4_taylor_3SWA,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "del _,softmaxOut,model,lit_model,checkpoint,test_loader; gc.collect();torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preds for B4 focal cosine loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsPath = {0:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\avgWeights\\_Avg_fold_0.ckpt',\n",
    "              1:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\avgWeights\\_Avg_fold_1.ckpt',\n",
    "              2:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\avgWeights\\_Avg_fold_2.ckpt',\n",
    "              3:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\avgWeights\\_Avg_fold_3.ckpt',\n",
    "              4:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\avgWeights\\_Avg_fold_4.ckpt'\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.60it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:22<00:00,  1.62it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:22<00:00,  1.62it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:22<00:00,  1.62it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:23<00:00,  1.61it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "preds_effnet_b4 = np.zeros((len(labels),5))\n",
    "\n",
    "train_img_path = 'C:/Users/Kaggle/Leaf_Classification/input/train_images/'\n",
    "TTA = TTA\n",
    "for f in range(5):    \n",
    "    softmaxOut = 0.\n",
    "    print(f\"Prediction for fold:{f}\")\n",
    "    modelPath = modelsPath[f]\n",
    "    model = Net_B4_newhead()\n",
    "    lit_model = LitCassava(model)\n",
    "    checkpoint = torch.load(modelPath, map_location=lambda storage, loc: storage)\n",
    "    lit_model.load_state_dict(checkpoint)      \n",
    "#    lit_model.load_state_dict(checkpoint['state_dict'])  \n",
    "    lit_model.model.eval()\n",
    "    lit_model.model.cuda()\n",
    "    for tta in range(TTA):\n",
    "        _,test_loader,valid_ix = getloader(labels,path=train_img_path,bs=32,fold=f,tta=tta)\n",
    "        predictions = []\n",
    "        softmaxOut+= (getPreds(test_loader,lit_model,logitsOut=True))\n",
    "    preds_effnet_b4[valid_ix,:] = np.vstack(softmaxOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean_effnetb4 = preds_effnet_b4.copy()\n",
    "preds_mean_effnetb4[:,0]= preds_effnet_b4[:,0]/(1+np.sqrt(0.05))\n",
    "preds_mean_effnetb4[:,1]= preds_effnet_b4[:,1]/(1+np.sqrt(0.102))\n",
    "preds_mean_effnetb4[:,2]= preds_effnet_b4[:,2]/(1+np.sqrt(0.111))\n",
    "preds_mean_effnetb4[:,3]= preds_effnet_b4[:,3]/(1+np.sqrt(0.614)) #### not the exact frequency stats here, instead of 0.614, we have used 0.4 \n",
    "preds_mean_effnetb4[:,4]= preds_effnet_b4[:,4]/(1+np.sqrt(0.12))\n",
    "\n",
    "classOut = np.argmax(preds_mean_effnetb4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8961069308781605, 0.8982100294433799)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels.label,classOut),accuracy_score(labels.label,np.argmax(preds_effnet_b4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "del _,softmaxOut,model,lit_model,checkpoint,test_loader; gc.collect();torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble b4 with deit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = pd.DataFrame()\n",
    "res_['b4_contrib'] = 0\n",
    "#res['b5_contrib'] = 0\n",
    "res_['deit_contrib'] = 0\n",
    "res_ ['Accuracy'] = 0\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(0,1,0.01):\n",
    "    b4_contrib = i\n",
    "    deit_contrib = 1-i\n",
    "    #print(i,j,1-i-j)\n",
    "    ens_preds = (b4_contrib*preds_effnet_b4+deit_contrib*preds_DEIT)\n",
    "    res_.loc[count,'b4_contrib'] = i\n",
    "    res_.loc[count,'deit_contrib'] = 1-i\n",
    "    res_.loc[count,'Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds,1))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b4_contrib</th>\n",
       "      <th>deit_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.900547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.900453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.900453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.900407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.900360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.894798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.894658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.894331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.894097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.893396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    b4_contrib  deit_contrib  Accuracy\n",
       "63        0.63          0.37  0.900547\n",
       "55        0.55          0.45  0.900453\n",
       "57        0.57          0.43  0.900453\n",
       "59        0.59          0.41  0.900407\n",
       "49        0.49          0.51  0.900360\n",
       "..         ...           ...       ...\n",
       "4         0.04          0.96  0.894798\n",
       "3         0.03          0.97  0.894658\n",
       "2         0.02          0.98  0.894331\n",
       "1         0.01          0.99  0.894097\n",
       "0         0.00          1.00  0.893396\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_.sort_values(by=['Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = pd.DataFrame()\n",
    "res_['b4_contrib'] = 0\n",
    "#res['b5_contrib'] = 0\n",
    "res_['seresnext_contrib'] = 0\n",
    "res_ ['Accuracy'] = 0\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(0,1,0.01):\n",
    "    b4_contrib = i\n",
    "    seresnext_contrib = 1-i\n",
    "    #print(i,j,1-i-j)\n",
    "    ens_preds = (b4_contrib*preds_effnet_b4+seresnext_contrib*preds_seresnext)\n",
    "    res_.loc[count,'b4_contrib'] = i\n",
    "    res_.loc[count,'seresnext_contrib'] = 1-i\n",
    "    res_.loc[count,'Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds,1))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b4_contrib</th>\n",
       "      <th>seresnext_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.901575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.901482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.901482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.901435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.901388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.898490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.897789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.897556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.896247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.895406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    b4_contrib  seresnext_contrib  Accuracy\n",
       "21        0.21               0.79  0.901575\n",
       "20        0.20               0.80  0.901482\n",
       "18        0.18               0.82  0.901482\n",
       "17        0.17               0.83  0.901435\n",
       "22        0.22               0.78  0.901388\n",
       "..         ...                ...       ...\n",
       "4         0.04               0.96  0.898490\n",
       "3         0.03               0.97  0.897789\n",
       "2         0.02               0.98  0.897556\n",
       "1         0.01               0.99  0.896247\n",
       "0         0.00               1.00  0.895406\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_.sort_values(by=['Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble deit with b4 taylor loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = pd.DataFrame()\n",
    "res_['b4_taylor_contrib'] = 0\n",
    "#res['b5_contrib'] = 0\n",
    "res_['deit_contrib'] = 0\n",
    "res_ ['Accuracy'] = 0\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(0,1,0.01):\n",
    "    b4_contrib = i\n",
    "    deit_contrib = 1-i\n",
    "    #print(i,j,1-i-j)\n",
    "    ens_preds = (b4_contrib*preds_effnet_b4_taylor+deit_contrib*preds_DEIT)\n",
    "    res_.loc[count,'b4_taylor_contrib'] = i\n",
    "    res_.loc[count,'deit_contrib'] = 1-i\n",
    "    res_.loc[count,'Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds,1))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b4_taylor_contrib</th>\n",
       "      <th>deit_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.900033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.899986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.899893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.899893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.899893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.895079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.894845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.894565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.894191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.893396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    b4_taylor_contrib  deit_contrib  Accuracy\n",
       "63               0.63          0.37  0.900033\n",
       "64               0.64          0.36  0.899986\n",
       "62               0.62          0.38  0.899893\n",
       "49               0.49          0.51  0.899893\n",
       "66               0.66          0.34  0.899893\n",
       "..                ...           ...       ...\n",
       "4                0.04          0.96  0.895079\n",
       "3                0.03          0.97  0.894845\n",
       "2                0.02          0.98  0.894565\n",
       "1                0.01          0.99  0.894191\n",
       "0                0.00          1.00  0.893396\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_.sort_values(by=['Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble seresnext with b4 taylor loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = pd.DataFrame()\n",
    "res_['b4_taylor_contrib'] = 0\n",
    "#res['b5_contrib'] = 0\n",
    "res_['seresnext_contrib'] = 0\n",
    "res_ ['Accuracy'] = 0\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(0,1,0.01):\n",
    "    b4_contrib = i\n",
    "    seresnext_contrib = 1-i\n",
    "    #print(i,j,1-i-j)\n",
    "    ens_preds = (b4_contrib*preds_effnet_b4_taylor+seresnext_contrib*preds_seresnext)\n",
    "    res_.loc[count,'b4_taylor_contrib'] = i\n",
    "    res_.loc[count,'seresnext_contrib'] = 1-i\n",
    "    res_.loc[count,'Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds,1))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b4_taylor_contrib</th>\n",
       "      <th>seresnext_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.900126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.900033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.900033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.899986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.899846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.896995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.896855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.896714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.896013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.895406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    b4_taylor_contrib  seresnext_contrib  Accuracy\n",
       "10               0.10               0.90  0.900126\n",
       "9                0.09               0.91  0.900033\n",
       "11               0.11               0.89  0.900033\n",
       "13               0.13               0.87  0.899986\n",
       "17               0.17               0.83  0.899846\n",
       "..                ...                ...       ...\n",
       "98               0.98               0.02  0.896995\n",
       "99               0.99               0.01  0.896855\n",
       "2                0.02               0.98  0.896714\n",
       "1                0.01               0.99  0.896013\n",
       "0                0.00               1.00  0.895406\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_.sort_values(by=['Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble deit+seresnext+b4 focal cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res['b4_contrib'] = 0\n",
    "res['deit_contrib'] = 0\n",
    "res['seresnext_contrib'] = 0\n",
    "res ['Accuracy'] = 0\n",
    "res ['Adj_Accuracy'] = 0\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(0,1,0.01):\n",
    "    for j in np.arange(0,1-i,0.01):\n",
    "        b4_contrib = i\n",
    "        deit_contrib = j\n",
    "        seresnext_contrib = 1-i-j\n",
    "        #print(i,j,1-i-j)\n",
    "        ens_preds_adj = (b4_contrib*preds_mean_effnetb4+seresnext_contrib*preds_mean_seresnext+deit_contrib*preds_mean_DEIT)\n",
    "        ens_preds = (b4_contrib*preds_effnet_b4+seresnext_contrib*preds_seresnext+deit_contrib*preds_DEIT)\n",
    "        res.loc[count,'b4_contrib'] = i\n",
    "        res.loc[count,'seresnext_contrib'] = 1-i-j\n",
    "        res.loc[count,'deit_contrib'] = j\n",
    "        res.loc[count,'Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds,1))\n",
    "        res.loc[count,'Adj_Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds_adj,1))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b4_contrib</th>\n",
       "      <th>deit_contrib</th>\n",
       "      <th>seresnext_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Adj_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.903024</td>\n",
       "      <td>0.900967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.902930</td>\n",
       "      <td>0.900967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.902930</td>\n",
       "      <td>0.901295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.902837</td>\n",
       "      <td>0.901154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.902837</td>\n",
       "      <td>0.901108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.894331</td>\n",
       "      <td>0.892882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.894284</td>\n",
       "      <td>0.892462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.894191</td>\n",
       "      <td>0.892742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.894191</td>\n",
       "      <td>0.892649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.894051</td>\n",
       "      <td>0.892275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5062 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      b4_contrib  deit_contrib  seresnext_contrib  Accuracy  Adj_Accuracy\n",
       "2056        0.23          0.09               0.68  0.903024      0.900967\n",
       "1978        0.22          0.09               0.69  0.902930      0.900967\n",
       "1979        0.22          0.10               0.68  0.902930      0.901295\n",
       "1738        0.19          0.09               0.72  0.902837      0.901154\n",
       "1819        0.20          0.09               0.71  0.902837      0.901108\n",
       "...          ...           ...                ...       ...           ...\n",
       "197         0.01          0.97               0.02  0.894331      0.892882\n",
       "98          0.00          0.98               0.02  0.894284      0.892462\n",
       "198         0.01          0.98               0.01  0.894191      0.892742\n",
       "97          0.00          0.97               0.03  0.894191      0.892649\n",
       "99          0.00          0.99               0.01  0.894051      0.892275\n",
       "\n",
       "[5062 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(by=['Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b4_contrib</th>\n",
       "      <th>deit_contrib</th>\n",
       "      <th>seresnext_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Adj_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.901622</td>\n",
       "      <td>0.902229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.901528</td>\n",
       "      <td>0.902183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.901902</td>\n",
       "      <td>0.902136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.901855</td>\n",
       "      <td>0.902089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.901996</td>\n",
       "      <td>0.902042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.894191</td>\n",
       "      <td>0.892742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.894191</td>\n",
       "      <td>0.892649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.894331</td>\n",
       "      <td>0.892649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.894284</td>\n",
       "      <td>0.892462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.894051</td>\n",
       "      <td>0.892275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5062 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      b4_contrib  deit_contrib  seresnext_contrib  Accuracy  Adj_Accuracy\n",
       "1232        0.13          0.10               0.77  0.901622      0.902229\n",
       "1233        0.13          0.11               0.76  0.901528      0.902183\n",
       "1321        0.14          0.12               0.74  0.901902      0.902136\n",
       "1144        0.12          0.10               0.78  0.901855      0.902089\n",
       "1405        0.15          0.10               0.75  0.901996      0.902042\n",
       "...          ...           ...                ...       ...           ...\n",
       "198         0.01          0.98               0.01  0.894191      0.892742\n",
       "97          0.00          0.97               0.03  0.894191      0.892649\n",
       "96          0.00          0.96               0.04  0.894331      0.892649\n",
       "98          0.00          0.98               0.02  0.894284      0.892462\n",
       "99          0.00          0.99               0.01  0.894051      0.892275\n",
       "\n",
       "[5062 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(by=['Adj_Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preds for B5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsPath = {0:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b5_ns_sz_576_timm_finetune_TemperedLoss_10Epochs\\avgWeights\\_Avg_fold_0.ckpt',\n",
    "              1:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b5_ns_sz_576_timm_finetune_TemperedLoss_10Epochs\\avgWeights\\_Avg_fold_1.ckpt',\n",
    "              2:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b5_ns_sz_576_timm_finetune_TemperedLoss_10Epochs\\avgWeights\\_Avg_fold_2.ckpt',\n",
    "              3:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b5_ns_sz_576_timm_finetune_TemperedLoss_10Epochs\\avgWeights\\_Avg_fold_3.ckpt',\n",
    "              4:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b5_ns_sz_576_timm_finetune_TemperedLoss_10Epochs\\avgWeights\\_Avg_fold_4.ckpt'\n",
    "             }\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:36<00:00,  1.39it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:35<00:00,  1.41it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:34<00:00,  1.42it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:34<00:00,  1.41it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:34<00:00,  1.42it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:34<00:00,  1.41it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:34<00:00,  1.42it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:35<00:00,  1.41it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:34<00:00,  1.42it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:34<00:00,  1.41it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "preds_effnet_b5 = np.zeros((len(labels),5))\n",
    "\n",
    "train_img_path = 'C:/Users/Kaggle/Leaf_Classification/input/train_images/'\n",
    "TTA = TTA\n",
    "for f in range(5):\n",
    "    softmaxOut = 0.\n",
    "    print(f\"Prediction for fold:{f}\")\n",
    "    modelPath = modelsPath[f]\n",
    "    model = Net_B5()\n",
    "    lit_model = LitCassava(model)\n",
    "    checkpoint = torch.load(modelPath, map_location=lambda storage, loc: storage)\n",
    "    lit_model.load_state_dict(checkpoint)  \n",
    "    lit_model.model.eval()\n",
    "    lit_model.model.cuda()\n",
    "    for tta in range(TTA):\n",
    "        _,test_loader,valid_ix = getloader(labels,path=train_img_path,bs=32,fold=f,tta=tta)\n",
    "        predictions = []\n",
    "        softmaxOut+= (getPreds(test_loader,lit_model,logitsOut=True))\n",
    "    preds_effnet_b5[valid_ix,:] = np.vstack(softmaxOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean_effnetb5 = preds_effnet_b5.copy()\n",
    "preds_mean_effnetb5[:,0]= preds_effnet_b5[:,0]/(1+np.sqrt(0.05))\n",
    "preds_mean_effnetb5[:,1]= preds_effnet_b5[:,1]/(1+np.sqrt(0.102))\n",
    "preds_mean_effnetb5[:,2]= preds_effnet_b5[:,2]/(1+np.sqrt(0.111))\n",
    "preds_mean_effnetb5[:,3]= preds_effnet_b5[:,3]/(1+np.sqrt(0.614)) #### not the exact frequency stats here, instead of 0.614, we have used 0.4 \n",
    "preds_mean_effnetb5[:,4]= preds_effnet_b5[:,4]/(1+np.sqrt(0.12))\n",
    "\n",
    "classOut = np.argmax(preds_mean_effnetb5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8945646585969996, 0.8968079637332337)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels.label,classOut),accuracy_score(labels.label,np.argmax(preds_effnet_b5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "del _,softmaxOut,model,lit_model,checkpoint,test_loader; gc.collect();torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res['b4_contrib'] = 0\n",
    "res['b5_contrib'] = 0\n",
    "res['seresnext_contrib'] = 0\n",
    "res ['Accuracy'] = 0\n",
    "res ['Adj_Accuracy'] = 0\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(0,1,0.01):\n",
    "    for j in np.arange(0,1-i,0.01):\n",
    "        b4_contrib = i\n",
    "        b5_contrib = j\n",
    "        seresnext_contrib = 1-i-j\n",
    "        #print(i,j,1-i-j)\n",
    "        ens_preds_adj = (b4_contrib*preds_mean_effnetb4+seresnext_contrib*preds_mean_seresnext+b5_contrib*preds_mean_effnetb5)\n",
    "        ens_preds = (b4_contrib*preds_effnet_b4+seresnext_contrib*preds_seresnext+b5_contrib*preds_effnet_b5)\n",
    "        res.loc[count,'b4_contrib'] = i\n",
    "        res.loc[count,'seresnext_contrib'] = 1-i-j\n",
    "        res.loc[count,'b5_contrib'] = j\n",
    "        res.loc[count,'Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds,1))\n",
    "        res.loc[count,'Adj_Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds_adj,1))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b4_contrib</th>\n",
       "      <th>b5_contrib</th>\n",
       "      <th>seresnext_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Adj_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.903071</td>\n",
       "      <td>0.902276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.903024</td>\n",
       "      <td>0.902136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.902977</td>\n",
       "      <td>0.902276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.902930</td>\n",
       "      <td>0.902229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.902884</td>\n",
       "      <td>0.902183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.896761</td>\n",
       "      <td>0.894705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.896387</td>\n",
       "      <td>0.895499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.896247</td>\n",
       "      <td>0.895546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.895967</td>\n",
       "      <td>0.894798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.895406</td>\n",
       "      <td>0.894518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5062 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      b4_contrib  b5_contrib  seresnext_contrib  Accuracy  Adj_Accuracy\n",
       "1146        0.12        0.12               0.76  0.903071      0.902276\n",
       "1233        0.13        0.11               0.76  0.903024      0.902136\n",
       "1234        0.13        0.12               0.75  0.902977      0.902276\n",
       "1145        0.12        0.11               0.77  0.902930      0.902229\n",
       "1055        0.11        0.10               0.79  0.902884      0.902183\n",
       "...          ...         ...                ...       ...           ...\n",
       "99          0.00        0.99               0.01  0.896761      0.894705\n",
       "2           0.00        0.02               0.98  0.896387      0.895499\n",
       "100         0.01        0.00               0.99  0.896247      0.895546\n",
       "1           0.00        0.01               0.99  0.895967      0.894798\n",
       "0           0.00        0.00               1.00  0.895406      0.894518\n",
       "\n",
       "[5062 rows x 5 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(by=['Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b4_contrib</th>\n",
       "      <th>b5_contrib</th>\n",
       "      <th>seresnext_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Adj_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.901575</td>\n",
       "      <td>0.903024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.902229</td>\n",
       "      <td>0.903024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.902556</td>\n",
       "      <td>0.903024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.901668</td>\n",
       "      <td>0.903024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.902556</td>\n",
       "      <td>0.903024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.896855</td>\n",
       "      <td>0.895266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.896901</td>\n",
       "      <td>0.895125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.895967</td>\n",
       "      <td>0.894798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.896761</td>\n",
       "      <td>0.894705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.895406</td>\n",
       "      <td>0.894518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5062 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      b4_contrib  b5_contrib  seresnext_contrib  Accuracy  Adj_Accuracy\n",
       "416         0.04        0.22               0.74  0.901575      0.903024\n",
       "1744        0.19        0.15               0.66  0.902229      0.903024\n",
       "975         0.10        0.20               0.70  0.902556      0.903024\n",
       "415         0.04        0.21               0.75  0.901668      0.903024\n",
       "885         0.09        0.21               0.70  0.902556      0.903024\n",
       "...          ...         ...                ...       ...           ...\n",
       "97          0.00        0.97               0.03  0.896855      0.895266\n",
       "98          0.00        0.98               0.02  0.896901      0.895125\n",
       "1           0.00        0.01               0.99  0.895967      0.894798\n",
       "99          0.00        0.99               0.01  0.896761      0.894705\n",
       "0           0.00        0.00               1.00  0.895406      0.894518\n",
       "\n",
       "[5062 rows x 5 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(by=['Adj_Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnest50d_1s4x24d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsPath = {0:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\resnest50d_1s4x24d_sz_576_Mixup_0.3_timm_newhead\\avgWeights\\_Avg_fold_0.ckpt',\n",
    "              1:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\resnest50d_1s4x24d_sz_576_Mixup_0.3_timm_newhead\\avgWeights\\_Avg_fold_1.ckpt',\n",
    "              2:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\resnest50d_1s4x24d_sz_576_Mixup_0.3_timm_newhead\\avgWeights\\_Avg_fold_2.ckpt',\n",
    "              3:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\resnest50d_1s4x24d_sz_576_Mixup_0.3_timm_newhead\\avgWeights\\_Avg_fold_3.ckpt',\n",
    "              4:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\resnest50d_1s4x24d_sz_576_Mixup_0.3_timm_newhead\\avgWeights\\_Avg_fold_4.ckpt'\n",
    "             }\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:25<00:00,  1.57it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:25<00:00,  1.57it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:25<00:00,  1.57it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:25<00:00,  1.57it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:25<00:00,  1.58it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:25<00:00,  1.57it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:25<00:00,  1.57it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:25<00:00,  1.57it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:25<00:00,  1.58it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:25<00:00,  1.57it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "preds_resnest50d = np.zeros((len(labels),5))\n",
    "\n",
    "train_img_path = 'C:/Users/Kaggle/Leaf_Classification/input/train_images/'\n",
    "TTA = TTA\n",
    "for f in range(5):\n",
    "    softmaxOut = 0.\n",
    "    print(f\"Prediction for fold:{f}\")\n",
    "    modelPath = modelsPath[f]\n",
    "    model = resnest50d()\n",
    "    lit_model = LitCassava(model)\n",
    "    checkpoint = torch.load(modelPath, map_location=lambda storage, loc: storage)\n",
    "    lit_model.load_state_dict(checkpoint)  \n",
    "    lit_model.model.eval()\n",
    "    lit_model.model.cuda()\n",
    "    for tta in range(TTA):\n",
    "        _,test_loader,valid_ix = getloader(labels,path=train_img_path,bs=32,fold=f,tta=tta)\n",
    "        predictions = []\n",
    "        softmaxOut+= (getPreds(test_loader,lit_model,logitsOut=True))\n",
    "    preds_resnest50d[valid_ix,:] = np.vstack(softmaxOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean_resnest50d = preds_resnest50d.copy()\n",
    "preds_mean_resnest50d[:,0]= preds_resnest50d[:,0]/(1+np.sqrt(0.05))\n",
    "preds_mean_resnest50d[:,1]= preds_resnest50d[:,1]/(1+np.sqrt(0.102))\n",
    "preds_mean_resnest50d[:,2]= preds_resnest50d[:,2]/(1+np.sqrt(0.111))\n",
    "preds_mean_resnest50d[:,3]= preds_resnest50d[:,3]/(1+np.sqrt(0.614)) #### not the exact frequency stats here, instead of 0.614, we have used 0.4 \n",
    "preds_mean_resnest50d[:,4]= preds_resnest50d[:,4]/(1+np.sqrt(0.12))\n",
    "\n",
    "classOut = np.argmax(preds_mean_resnest50d,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8924148245081086, 0.8951254848810581)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels.label,classOut),accuracy_score(labels.label,np.argmax(preds_resnest50d,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnext50D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsPath = {0:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\resnext50_32x4d_sz_576_Mixup_0.3_timm_newhead\\avgWeights\\_Avg_fold_0.ckpt',\n",
    "              1:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\resnext50_32x4d_sz_576_Mixup_0.3_timm_newhead\\avgWeights\\_Avg_fold_1.ckpt',\n",
    "              2:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\resnext50_32x4d_sz_576_Mixup_0.3_timm_newhead\\avgWeights\\_Avg_fold_2.ckpt',\n",
    "              3:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\resnext50_32x4d_sz_576_Mixup_0.3_timm_newhead\\avgWeights\\_Avg_fold_3.ckpt',\n",
    "              4:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\resnext50_32x4d_sz_576_Mixup_0.3_timm_newhead\\avgWeights\\_Avg_fold_4.ckpt'\n",
    "             }\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:35<00:00,  1.41it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:35<00:00,  1.40it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:34<00:00,  1.41it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:35<00:00,  1.41it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:34<00:00,  1.41it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:35<00:00,  1.40it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:34<00:00,  1.41it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:36<00:00,  1.39it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for fold:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 0 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:35<00:00,  1.40it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TTA: 1 and DEIT:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134/134 [01:36<00:00,  1.39it/s]\n",
      "C:\\Users\\Anaconda_Stuff\\envs\\Pytorch_17_cuda11\\lib\\site-packages\\ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "preds_resnext50d = np.zeros((len(labels),5))\n",
    "\n",
    "train_img_path = 'C:/Users/Kaggle/Leaf_Classification/input/train_images/'\n",
    "TTA = TTA\n",
    "for f in range(5):\n",
    "    softmaxOut = 0.\n",
    "    print(f\"Prediction for fold:{f}\")\n",
    "    modelPath = modelsPath[f]\n",
    "    model = ResnextNet50d()\n",
    "    lit_model = LitCassava(model)\n",
    "    checkpoint = torch.load(modelPath, map_location=lambda storage, loc: storage)\n",
    "#     lit_model.load_state_dict(checkpoint['state_dict'])  \n",
    "    lit_model.load_state_dict(checkpoint)  \n",
    "    lit_model.model.eval()\n",
    "    lit_model.model.cuda()\n",
    "    for tta in range(TTA):\n",
    "        _,test_loader,valid_ix = getloader(labels,path=train_img_path,bs=32,fold=f,tta=tta)\n",
    "        predictions = []\n",
    "        softmaxOut+= (getPreds(test_loader,lit_model,logitsOut=True))\n",
    "    preds_resnext50d[valid_ix,:] = np.vstack(softmaxOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean_resnext50d = preds_resnext50d.copy()\n",
    "preds_mean_resnext50d[:,0]= preds_resnext50d[:,0]/(1+np.sqrt(0.05))\n",
    "preds_mean_resnext50d[:,1]= preds_resnext50d[:,1]/(1+np.sqrt(0.102))\n",
    "preds_mean_resnext50d[:,2]= preds_resnext50d[:,2]/(1+np.sqrt(0.111))\n",
    "preds_mean_resnext50d[:,3]= preds_resnext50d[:,3]/(1+np.sqrt(0.614)) #### not the exact frequency stats here, instead of 0.614, we have used 0.4 \n",
    "preds_mean_resnext50d[:,4]= preds_resnext50d[:,4]/(1+np.sqrt(0.12))\n",
    "\n",
    "classOut = np.argmax(preds_mean_resnext50d,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8906856101322616, 0.8951254848810581)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels.label,classOut),accuracy_score(labels.label,np.argmax(preds_resnest50d,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999998\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999998\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999998\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999998\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999998\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999998\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999998\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "res_all4 = pd.DataFrame()\n",
    "res_all4['b4_contrib'] = 0\n",
    "res_all4['b5_contrib'] = 0\n",
    "res_all4['seresnext_contrib'] = 0\n",
    "res_all4['resnest_contrib'] = 0\n",
    "\n",
    "res_all4 ['Accuracy'] = 0\n",
    "res_all4 ['Adj_Accuracy'] = 0\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(0,1,0.05):\n",
    "    for j in np.arange(0,1-i,0.05):\n",
    "        for k in np.arange(0,1-i-j,0.05):\n",
    "            b4_contrib = i\n",
    "            b5_contrib = j\n",
    "            seresnext_contrib = k\n",
    "            resnest_contrib = 1-i-j-k\n",
    "            print(b4_contrib+b5_contrib+seresnext_contrib+resnest_contrib)\n",
    "            #assert b4_contrib+b5_contrib+seresnext_contrib+resnest_contrib==1.\n",
    "            #print(i,j,k,1-(i+j+k))\n",
    "            ens_preds_adj = (b4_contrib*preds_mean_effnetb4+seresnext_contrib*preds_mean_seresnext+b5_contrib*preds_mean_effnetb5+resnest_contrib*preds_mean_resnest50d)\n",
    "            ens_preds = (b4_contrib*preds_effnet_b4+seresnext_contrib*preds_seresnext+b5_contrib*preds_effnet_b5+resnest_contrib*preds_resnest50d)\n",
    "            res_all4.loc[count,'b4_contrib'] = i\n",
    "            res_all4.loc[count,'seresnext_contrib'] = j\n",
    "            res_all4.loc[count,'b5_contrib'] = k\n",
    "            res_all4.loc[count,'resnest_contrib'] = 1-i-j-k\n",
    "            res_all4.loc[count,'Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds,1))\n",
    "            res_all4.loc[count,'Adj_Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds_adj,1))\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b4_contrib</th>\n",
       "      <th>b5_contrib</th>\n",
       "      <th>seresnext_contrib</th>\n",
       "      <th>resnest_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Adj_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.903444</td>\n",
       "      <td>0.902463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.903444</td>\n",
       "      <td>0.902556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.903351</td>\n",
       "      <td>0.902603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.903351</td>\n",
       "      <td>0.902369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.903257</td>\n",
       "      <td>0.902323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.897088</td>\n",
       "      <td>0.895219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.896761</td>\n",
       "      <td>0.895593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.896294</td>\n",
       "      <td>0.895079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.896013</td>\n",
       "      <td>0.894798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.895125</td>\n",
       "      <td>0.892415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1549 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     b4_contrib  b5_contrib  seresnext_contrib  resnest_contrib  Accuracy  \\\n",
       "444        0.10        0.45               0.10             0.35  0.903444   \n",
       "254        0.05        0.35               0.10             0.50  0.903444   \n",
       "445        0.10        0.50               0.10             0.30  0.903351   \n",
       "255        0.05        0.40               0.10             0.45  0.903351   \n",
       "443        0.10        0.40               0.10             0.40  0.903257   \n",
       "..          ...         ...                ...              ...       ...   \n",
       "209        0.00        0.00               0.95             0.05  0.897088   \n",
       "17         0.00        0.85               0.00             0.15  0.896761   \n",
       "18         0.00        0.90               0.00             0.10  0.896294   \n",
       "19         0.00        0.95               0.00             0.05  0.896013   \n",
       "0          0.00        0.00               0.00             1.00  0.895125   \n",
       "\n",
       "     Adj_Accuracy  \n",
       "444      0.902463  \n",
       "254      0.902556  \n",
       "445      0.902603  \n",
       "255      0.902369  \n",
       "443      0.902323  \n",
       "..            ...  \n",
       "209      0.895219  \n",
       "17       0.895593  \n",
       "18       0.895079  \n",
       "19       0.894798  \n",
       "0        0.892415  \n",
       "\n",
       "[1549 rows x 6 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all4.sort_values(by=['Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b4_contrib</th>\n",
       "      <th>b5_contrib</th>\n",
       "      <th>seresnext_contrib</th>\n",
       "      <th>resnest_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Adj_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.902697</td>\n",
       "      <td>0.903164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.901996</td>\n",
       "      <td>0.903117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.901996</td>\n",
       "      <td>0.903117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.901996</td>\n",
       "      <td>0.903024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.902042</td>\n",
       "      <td>0.903024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.897088</td>\n",
       "      <td>0.895219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.896294</td>\n",
       "      <td>0.895079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.897088</td>\n",
       "      <td>0.894985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.896013</td>\n",
       "      <td>0.894798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.895125</td>\n",
       "      <td>0.892415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1549 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     b4_contrib  b5_contrib  seresnext_contrib  resnest_contrib  Accuracy  \\\n",
       "458        0.10        0.35               0.15             0.40  0.902697   \n",
       "289        0.05        0.45               0.20             0.30  0.901996   \n",
       "303        0.05        0.40               0.25             0.30  0.901996   \n",
       "286        0.05        0.30               0.20             0.45  0.901996   \n",
       "292        0.05        0.60               0.20             0.15  0.902042   \n",
       "..          ...         ...                ...              ...       ...   \n",
       "209        0.00        0.00               0.95             0.05  0.897088   \n",
       "18         0.00        0.90               0.00             0.10  0.896294   \n",
       "1          0.00        0.05               0.00             0.95  0.897088   \n",
       "19         0.00        0.95               0.00             0.05  0.896013   \n",
       "0          0.00        0.00               0.00             1.00  0.895125   \n",
       "\n",
       "     Adj_Accuracy  \n",
       "458      0.903164  \n",
       "289      0.903117  \n",
       "303      0.903117  \n",
       "286      0.903024  \n",
       "292      0.903024  \n",
       "..            ...  \n",
       "209      0.895219  \n",
       "18       0.895079  \n",
       "1        0.894985  \n",
       "19       0.894798  \n",
       "0        0.892415  \n",
       "\n",
       "[1549 rows x 6 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all4.sort_values(by=['Adj_Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_DEIT\n",
    "#preds_mean_DEIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "res_all4 = pd.DataFrame()\n",
    "res_all4['DEIT_contrib'] = 0\n",
    "res_all4['b5_contrib'] = 0\n",
    "res_all4['seresnext_contrib'] = 0\n",
    "res_all4['resnest_contrib'] = 0\n",
    "\n",
    "res_all4 ['Accuracy'] = 0\n",
    "res_all4 ['Adj_Accuracy'] = 0\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(0,1,0.05):\n",
    "    for j in np.arange(0,1-i,0.05):\n",
    "        for k in np.arange(0,1-i-j,0.05):\n",
    "            DEIT_contrib = i\n",
    "            b5_contrib = j \n",
    "            seresnext_contrib = k = 0 \n",
    "            resnest_contrib = 1-i-j-k\n",
    "            print(DEIT_contrib+b5_contrib+seresnext_contrib+resnest_contrib)\n",
    "            #assert b4_contrib+b5_contrib+seresnext_contrib+resnest_contrib==1.\n",
    "            #print(i,j,k,1-(i+j+k))\n",
    "            ens_preds_adj = (DEIT_contrib*preds_mean_DEIT+seresnext_contrib*preds_mean_seresnext+b5_contrib*preds_mean_effnetb5+resnest_contrib*preds_mean_resnest50d)\n",
    "            ens_preds = (DEIT_contrib*preds_DEIT+seresnext_contrib*preds_seresnext+b5_contrib*preds_effnet_b5+resnest_contrib*preds_resnest50d)\n",
    "            res_all4.loc[count,'DEIT_contrib'] = i\n",
    "            res_all4.loc[count,'seresnext_contrib'] = j\n",
    "            res_all4.loc[count,'b5_contrib'] = k\n",
    "            res_all4.loc[count,'resnest_contrib'] = 1-i-j-k\n",
    "            res_all4.loc[count,'Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds,1))\n",
    "            res_all4.loc[count,'Adj_Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds_adj,1))\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.50621823],\n",
       "       [0.50621823, 1.        ]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.max(preds_DEIT,1),np.max(preds_effnet_b4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.6057979],\n",
       "       [0.6057979, 1.       ]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.max(preds_DEIT,1),np.max(preds_effnet_b5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.55770814],\n",
       "       [0.55770814, 1.        ]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.max(preds_DEIT,1),np.max(preds_seresnext,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.48777121],\n",
       "       [0.48777121, 1.        ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.max(preds_DEIT,1),np.max(preds_resnest50d,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.88647709],\n",
       "       [0.88647709, 1.        ]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.max(preds_seresnext,1),np.max(preds_resnest50d,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.51496308],\n",
       "       [0.51496308, 1.        ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.max(preds_effnet_b4_taylor,1),np.max(preds_effnet_b4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEIT_contrib</th>\n",
       "      <th>b5_contrib</th>\n",
       "      <th>seresnext_contrib</th>\n",
       "      <th>resnest_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Adj_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.901809</td>\n",
       "      <td>0.900266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.901809</td>\n",
       "      <td>0.900266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.901809</td>\n",
       "      <td>0.900266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.901809</td>\n",
       "      <td>0.900266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.901809</td>\n",
       "      <td>0.900266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.894658</td>\n",
       "      <td>0.893163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.894658</td>\n",
       "      <td>0.893163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.894565</td>\n",
       "      <td>0.892602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.894565</td>\n",
       "      <td>0.892602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.894238</td>\n",
       "      <td>0.892415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1549 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DEIT_contrib  b5_contrib  seresnext_contrib  resnest_contrib  Accuracy  \\\n",
       "457           0.10         0.0               0.15             0.75  0.901809   \n",
       "451           0.10         0.0               0.15             0.75  0.901809   \n",
       "453           0.10         0.0               0.15             0.75  0.901809   \n",
       "454           0.10         0.0               0.15             0.75  0.901809   \n",
       "455           0.10         0.0               0.15             0.75  0.901809   \n",
       "...            ...         ...                ...              ...       ...   \n",
       "1541          0.85         0.0               0.00             0.15  0.894658   \n",
       "1540          0.85         0.0               0.00             0.15  0.894658   \n",
       "1545          0.90         0.0               0.00             0.10  0.894565   \n",
       "1546          0.90         0.0               0.00             0.10  0.894565   \n",
       "1548          0.95         0.0               0.00             0.05  0.894238   \n",
       "\n",
       "      Adj_Accuracy  \n",
       "457       0.900266  \n",
       "451       0.900266  \n",
       "453       0.900266  \n",
       "454       0.900266  \n",
       "455       0.900266  \n",
       "...            ...  \n",
       "1541      0.893163  \n",
       "1540      0.893163  \n",
       "1545      0.892602  \n",
       "1546      0.892602  \n",
       "1548      0.892415  \n",
       "\n",
       "[1549 rows x 6 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all4.sort_values(by=['Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66053358, 0.06623735, 0.03035879, 0.04691812, 0.19595216],\n",
       "       [0.04020101, 0.81589767, 0.02558246, 0.04431247, 0.0740064 ],\n",
       "       [0.00963956, 0.02137469, 0.80888516, 0.10435876, 0.05574183],\n",
       "       [0.00136799, 0.00395197, 0.01086791, 0.97834017, 0.00547196],\n",
       "       [0.07062476, 0.0508343 , 0.0523865 , 0.08420644, 0.741948  ]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(labels.label,np.argmax(preds_effnet_b4,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67525299, 0.06531739, 0.03035879, 0.04139834, 0.18767249],\n",
       "       [0.04385564, 0.82046597, 0.02558246, 0.03883052, 0.07126542],\n",
       "       [0.01047779, 0.02221291, 0.82145851, 0.08968986, 0.05616094],\n",
       "       [0.00182399, 0.00539596, 0.01329989, 0.97013224, 0.00934793],\n",
       "       [0.07489329, 0.0523865 , 0.05316259, 0.07489329, 0.74466434]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels.label,np.argmax(preds_mean_effnetb4,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65041398, 0.05703772, 0.02207912, 0.04139834, 0.22907084],\n",
       "       [0.04111466, 0.80584742, 0.02832344, 0.04339881, 0.08131567],\n",
       "       [0.01047779, 0.01927913, 0.81894384, 0.09974853, 0.05155071],\n",
       "       [0.00189998, 0.00395197, 0.01322389, 0.97362821, 0.00729594],\n",
       "       [0.06790842, 0.04889406, 0.04967016, 0.07916182, 0.75436554]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels.label,np.argmax(preds_effnet_b4_taylor,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66881325, 0.05611776, 0.02115915, 0.03679853, 0.21711132],\n",
       "       [0.04385564, 0.80813157, 0.02832344, 0.03974418, 0.07994518],\n",
       "       [0.01215423, 0.01886002, 0.82523051, 0.09178541, 0.05196982],\n",
       "       [0.00212798, 0.00509196, 0.01603587, 0.96572427, 0.01101991],\n",
       "       [0.0717889 , 0.04967016, 0.0508343 , 0.06790842, 0.75979821]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels.label,np.argmax(preds_mean_effnetb4_taylor,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64029439, 0.07543698, 0.0174793 , 0.04691812, 0.21987121],\n",
       "       [0.04888077, 0.80721791, 0.02375514, 0.04431247, 0.07583371],\n",
       "       [0.01383068, 0.0217938 , 0.77829003, 0.11986588, 0.06621961],\n",
       "       [0.00151999, 0.00395197, 0.01071591, 0.97606019, 0.00775194],\n",
       "       [0.06946061, 0.05277454, 0.04152115, 0.07838572, 0.75785797]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels.label,np.argmax(preds_DEIT,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66513339, 0.05979761, 0.02391904, 0.0450782 , 0.20607176],\n",
       "       [0.04202832, 0.81087254, 0.02878026, 0.03791686, 0.08040201],\n",
       "       [0.01424979, 0.01927913, 0.81559095, 0.09513831, 0.05574183],\n",
       "       [0.00227998, 0.00471196, 0.0129959 , 0.97256422, 0.00744794],\n",
       "       [0.07023671, 0.0516104 , 0.0516104 , 0.07062476, 0.75591773]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels.label,np.argmax(preds_effnet_b5,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64949402, 0.06623735, 0.02851886, 0.04231831, 0.21343146],\n",
       "       [0.04431247, 0.81269986, 0.02512563, 0.04385564, 0.0740064 ],\n",
       "       [0.01215423, 0.02221291, 0.79798826, 0.11525566, 0.05238894],\n",
       "       [0.00212798, 0.00357197, 0.01132391, 0.97689618, 0.00607995],\n",
       "       [0.06790842, 0.05432674, 0.05471478, 0.08187815, 0.74117191]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels.label,np.argmax(preds_resnest50d,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63845446, 0.05887764, 0.01931923, 0.05335787, 0.2299908 ],\n",
       "       [0.04248515, 0.80813157, 0.02329831, 0.04842394, 0.07766103],\n",
       "       [0.01173512, 0.01634535, 0.80134116, 0.1093881 , 0.06119028],\n",
       "       [0.00212798, 0.00341997, 0.0126919 , 0.97431221, 0.00744794],\n",
       "       [0.0717889 , 0.04656577, 0.04656577, 0.0814901 , 0.75358945]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels.label,np.argmax(preds_resnext50d,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65225391, 0.06623735, 0.01563937, 0.05151794, 0.21435143],\n",
       "       [0.04659662, 0.80630425, 0.0246688 , 0.04659662, 0.07583371],\n",
       "       [0.01257334, 0.02263202, 0.79086337, 0.11735122, 0.05658005],\n",
       "       [0.00220398, 0.00349597, 0.00949992, 0.97963216, 0.00516796],\n",
       "       [0.07566938, 0.05044626, 0.04811797, 0.08537059, 0.74039581]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels.label,np.argmax(preds_seresnext,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9024629620974903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.67985281, 0.06347746, 0.02115915, 0.04783809, 0.18767249],\n",
       "       [0.04294198, 0.82046597, 0.02421197, 0.04248515, 0.06989493],\n",
       "       [0.01131601, 0.01927913, 0.81181894, 0.10645432, 0.0511316 ],\n",
       "       [0.00151999, 0.00349597, 0.00980392, 0.98008816, 0.00509196],\n",
       "       [0.06752037, 0.04928211, 0.04967016, 0.07993791, 0.75358945]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b4_contrib = 0.18\n",
    "seresnext_contrib = 0.61\n",
    "b5_contrib = 0.21\n",
    "_ = (b4_contrib*preds_effnet_b4+seresnext_contrib*preds_seresnext+b5_contrib*preds_effnet_b5)\n",
    "print(accuracy_score(labels.label,np.argmax(_,1)))\n",
    "confusion_matrix(labels.label,np.argmax(_,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8993784175351685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65685373, 0.07175713, 0.0174793 , 0.04599816, 0.20791168],\n",
       "       [0.04705345, 0.81498401, 0.02192782, 0.04568296, 0.07035176],\n",
       "       [0.01131601, 0.02263202, 0.79002515, 0.11567477, 0.06035205],\n",
       "       [0.00151999, 0.00364797, 0.00889193, 0.98069615, 0.00524396],\n",
       "       [0.06713232, 0.04928211, 0.04346139, 0.08071401, 0.75941017]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deit_contrib = 0.15\n",
    "seresnext_contrib = 0.25\n",
    "resnest_contrib = 0.6\n",
    "_ = (deit_contrib*preds_DEIT+seresnext_contrib*preds_seresnext+resnest_contrib*preds_resnest50d)\n",
    "print(accuracy_score(labels.label,np.argmax(_,1)))\n",
    "confusion_matrix(labels.label,np.argmax(_,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res['b4_contrib'] = 0\n",
    "res['deit_contrib'] = 0\n",
    "res['seresnext_contrib'] = 0\n",
    "res ['Accuracy'] = 0\n",
    "res ['Adj_Accuracy'] = 0\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(0,1,0.01):\n",
    "    for j in np.arange(0,1-i,0.01):\n",
    "        b4_contrib = i\n",
    "        deit_contrib = j\n",
    "        seresnext_contrib = 1-i-j\n",
    "        #print(i,j,1-i-j)\n",
    "        ens_preds_adj = (b4_contrib*preds_mean_effnetb4+seresnext_contrib*preds_mean_seresnext+deit_contrib*preds_mean_DEIT)\n",
    "        ens_preds = (b4_contrib*preds_effnet_b4+seresnext_contrib*preds_seresnext+deit_contrib*preds_DEIT)\n",
    "        res.loc[count,'b4_contrib'] = i\n",
    "        res.loc[count,'seresnext_contrib'] = 1-i-j\n",
    "        res.loc[count,'deit_contrib'] = j\n",
    "        res.loc[count,'Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds,1))\n",
    "        res.loc[count,'Adj_Accuracy'] = accuracy_score(labels.label,np.argmax(ens_preds_adj,1))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b4_contrib</th>\n",
       "      <th>deit_contrib</th>\n",
       "      <th>seresnext_contrib</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Adj_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.903024</td>\n",
       "      <td>0.900967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.902930</td>\n",
       "      <td>0.900967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.902930</td>\n",
       "      <td>0.901295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.902837</td>\n",
       "      <td>0.901154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.902837</td>\n",
       "      <td>0.901108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.894331</td>\n",
       "      <td>0.892882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.894284</td>\n",
       "      <td>0.892462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.894191</td>\n",
       "      <td>0.892742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.894191</td>\n",
       "      <td>0.892649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.894051</td>\n",
       "      <td>0.892275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5062 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      b4_contrib  deit_contrib  seresnext_contrib  Accuracy  Adj_Accuracy\n",
       "2056        0.23          0.09               0.68  0.903024      0.900967\n",
       "1978        0.22          0.09               0.69  0.902930      0.900967\n",
       "1979        0.22          0.10               0.68  0.902930      0.901295\n",
       "1738        0.19          0.09               0.72  0.902837      0.901154\n",
       "1819        0.20          0.09               0.71  0.902837      0.901108\n",
       "...          ...           ...                ...       ...           ...\n",
       "197         0.01          0.97               0.02  0.894331      0.892882\n",
       "98          0.00          0.98               0.02  0.894284      0.892462\n",
       "198         0.01          0.98               0.01  0.894191      0.892742\n",
       "97          0.00          0.97               0.03  0.894191      0.892649\n",
       "99          0.00          0.99               0.01  0.894051      0.892275\n",
       "\n",
       "[5062 rows x 5 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(by=['Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    13158\n",
       "4     2577\n",
       "2     2386\n",
       "1     2189\n",
       "0     1087\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9023227555264757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65869365, 0.06531739, 0.02115915, 0.04783809, 0.20699172],\n",
       "       [0.04157149, 0.82366377, 0.02192782, 0.04339881, 0.0694381 ],\n",
       "       [0.0108969 , 0.02053646, 0.80469405, 0.10771165, 0.05616094],\n",
       "       [0.00136799, 0.00372397, 0.00911993, 0.98069615, 0.00509196],\n",
       "       [0.06790842, 0.04772992, 0.04307334, 0.07916182, 0.7621265 ]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deit_contrib = 0.25\n",
    "seresnext_contrib = 0.46\n",
    "b4_contrib = 0.29\n",
    "_ = (b4_contrib*preds_effnet_b4+seresnext_contrib*preds_seresnext+deit_contrib*preds_DEIT)\n",
    "print(accuracy_score(labels.label,np.argmax(_,1)))\n",
    "confusion_matrix(labels.label,np.argmax(_,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.614946\n",
       "4    0.120437\n",
       "2    0.111511\n",
       "1    0.102304\n",
       "0    0.050802\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.label.value_counts(sort=True,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9022760200028042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.67157314, 0.06531739, 0.02299908, 0.04783809, 0.19227231],\n",
       "       [0.04339881, 0.82229328, 0.02238465, 0.04339881, 0.06852444],\n",
       "       [0.00922045, 0.02137469, 0.80595138, 0.10729254, 0.05616094],\n",
       "       [0.00151999, 0.00372397, 0.00911993, 0.98054416, 0.00509196],\n",
       "       [0.0717889 , 0.04850601, 0.04346139, 0.07916182, 0.75708188]])"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mean = _.copy()\n",
    "_mean[:,0]= _mean[:,0]/(1+np.sqrt(0.025))\n",
    "_mean[:,1]= _mean[:,1]/(1+np.sqrt(0.07))\n",
    "_mean[:,2]= _mean[:,2]/(1+np.sqrt(.1))\n",
    "_mean[:,3]= _mean[:,3]/(1+np.sqrt(.1))#(0.614)) #### not the exact frequency stats here, instead of 0.614, we have used 0.4 \n",
    "_mean[:,4]= _mean[:,4]/(1+np.sqrt(.1))\n",
    "\n",
    "print(accuracy_score(labels.label,np.argmax(_mean,1)))\n",
    "confusion_matrix(labels.label,np.argmax(_mean,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.52753948, 0.1680009 , 0.14860645, 0.15585316, 0.8903946 ],\n",
       "       [1.26569419, 0.32308571, 0.21548103, 0.1957391 , 0.87965541],\n",
       "       [1.57603899, 0.13846657, 0.14343164, 0.14206283, 1.0265657 ],\n",
       "       ...,\n",
       "       [1.51861578, 0.18662444, 0.14304688, 0.15171286, 0.86184758],\n",
       "       [1.53035844, 0.16287115, 0.1513349 , 0.15543549, 0.94116129],\n",
       "       [1.53338288, 0.15829184, 0.15316321, 0.15516204, 1.02041654]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[ix[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 12\n",
      "0.902696639715848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.66789328, 0.06531739, 0.02483901, 0.04783809, 0.19411224],\n",
       "       [0.04202832, 0.82366377, 0.02238465, 0.04339881, 0.06852444],\n",
       "       [0.00838223, 0.02053646, 0.80720872, 0.10771165, 0.05616094],\n",
       "       [0.00136799, 0.00372397, 0.00911993, 0.98069615, 0.00509196],\n",
       "       [0.07062476, 0.04772992, 0.04346139, 0.07916182, 0.75902212]])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = (b4_contrib*preds_effnet_b4+seresnext_contrib*preds_seresnext+deit_contrib*preds_DEIT)\n",
    "newarray = np.zeros_like(_)\n",
    "ix = np.where(((np.argmax(_,1)==4)&((-_).argsort(1)[:,1]==0)&((_[:,4]-_[:,0])<.08)))\n",
    "#x1 = np.where(((np.argmax(_,1)==1)&((-_).argsort(1)[:,1]==0)&((_[:,1]-_[:,0])<0.01)))\n",
    "#ix1 = np.where(((np.argmax(_,1)==3)&((-_).argsort(1)[:,1]==2)&((_[:,3]-_[:,2])<.2)))\n",
    "ix2 = np.where(((np.argmax(_,1)==3)&((-_).argsort(1)[:,1]==4)&((_[:,3]-_[:,4])<.0)))\n",
    "ix3 = np.where(((np.argmax(_,1)==0)&((-_).argsort(1)[:,1]==2)&((_[:,0]-_[:,2])<.25)))\n",
    "\n",
    "print(len(ix[0]),len(ix3[0]))\n",
    "\n",
    "for i in ix:\n",
    "    _[i,0] = _[i,0]+_[i,4]\n",
    "\n",
    "for i in ix3:\n",
    "    _[i,2] = _[i,2]+_[i,0]\n",
    "\n",
    "print(accuracy_score(labels.label,np.argmax(_,1)))\n",
    "confusion_matrix(labels.label,np.argmax(_,1),normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34285714285714286"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels.label.values[ix3]==2).sum()/len(ix3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.32269222, 1.54601742, 1.18670611, 1.23611781, 1.50371228,\n",
       "       1.09175843, 1.66068414, 1.08694288, 1.41845043, 1.26189423,\n",
       "       1.56120515, 1.54449279, 1.52015345, 1.42241056, 1.56228947,\n",
       "       1.12286624, 1.46789592, 1.46200109, 1.5317535 , 1.47725835,\n",
       "       1.12301962, 1.0480523 , 1.04060951, 1.35169366, 1.39142594,\n",
       "       1.55642648, 1.19459304, 1.57295559])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[ix][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61310751, 0.7292013 , 0.56588739, 0.58930318, 0.739897  ,\n",
       "       0.49879757, 0.7960869 , 0.5074941 , 0.6956923 , 0.61896792,\n",
       "       0.74351591, 0.73568622, 0.74512886, 0.68382771, 0.74548076,\n",
       "       0.55492171, 0.72873566, 0.71852799, 0.75283243, 0.71329008,\n",
       "       0.55952111, 0.52166591, 0.47769229, 0.65638027, 0.68074083,\n",
       "       0.7428829 , 0.5706035 , 0.75178909])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[ix][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newarray[ix][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newarray[ix][:,2] = 1\n",
    "#+= np.ones_like(newarray[ix][:,2])\n",
    "newarray[ix][:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newarray[ix][:,2]=newarray[ix][:,2] + 1\n",
    "newarray[ix][:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46870964, 0.06786407, 0.10899665, ..., 0.01660305, 0.13175307,\n",
       "       0.09849462])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[~ix][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "_[(np.argmax(_,1)==4)*((-_).argsort(1)[:,1]==0)*((_[:,4]-_[:,0]<0.1))][:,0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61310751, 0.7292013 , 0.56588739, 0.58930318, 0.739897  ,\n",
       "       0.49879757, 0.7960869 , 0.5074941 , 0.6956923 , 0.61896792,\n",
       "       0.74351591, 0.73568622, 0.74512886, 0.68382771, 0.74548076,\n",
       "       0.55492171, 0.72873566, 0.71852799, 0.75283243, 0.71329008,\n",
       "       0.55952111, 0.52166591, 0.47769229, 0.65638027, 0.68074083,\n",
       "       0.7428829 , 0.5706035 , 0.75178909])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[(np.argmax(_,1)==4)*((-_).argsort(1)[:,1]==0)*((_[:,4]-_[:,0]<0.1))][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(_[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
