{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import albumentations\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from albumentations.core.composition import Compose\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from typing import Any, Dict, List, Union, Optional\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import cv2\n",
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import numpy as np\n",
    "import timm\n",
    "from PIL import Image\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "pytorch_lightning.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_lightning.utilities.seed.seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "taylor_B4 = {0:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\0\\epoch=13_valid_loss=0.3129_valid_accuracy=0.9002.ckpt',\n",
    "             1: r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\1\\epoch=8_valid_loss=0.3055_valid_accuracy=0.9007.ckpt',\n",
    "             2: r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\2\\epoch=12_valid_loss=0.3124_valid_accuracy=0.8988.ckpt',\n",
    "             3: r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\3\\epoch=11_valid_loss=0.3364_valid_accuracy=0.8909.ckpt',\n",
    "             4:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\4\\epoch=9_valid_loss=0.3229_valid_accuracy=0.8916.ckpt',\n",
    "            }\n",
    "\n",
    "focalCosine_B4 = {0:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\0\\epoch=21_valid_loss=0.1313_valid_accuracy=0.8988.ckpt',\n",
    "             1: r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\1\\epoch=11_valid_loss=0.1244_valid_accuracy=0.9070.ckpt',\n",
    "             2: r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\2\\epoch=7_valid_loss=0.1304_valid_accuracy=0.8967.ckpt',\n",
    "             3: r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\3\\epoch=17_valid_loss=0.1344_valid_accuracy=0.8913.ckpt',\n",
    "             4:r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\4\\epoch=13_valid_loss=0.1341_valid_accuracy=0.8946.ckpt',\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runcustomSWA(modelMapping1=taylor_B4,modelMapping2=focalCosine_B4,outDir=r'C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Custom SWA\\B4_FocalCosine_B4_Taylor_TopModel_Each_Fold',fold=0):\n",
    "    \n",
    "    model1 = modelMapping1[fold]\n",
    "    model2 = modelMapping2[fold]\n",
    "    \n",
    "    print(modelMapping1[fold],print(modelMapping2[fold]))\n",
    "\n",
    "    swa_state_dict = torch.load(model1, map_location=lambda storage, loc: storage)['state_dict']\n",
    "    \n",
    "    for k,v in swa_state_dict.items():\n",
    "        swa_state_dict[k] = torch.zeros_like(v,dtype=torch.float32)\n",
    "        \n",
    "    for wts in [model1,model2]:\n",
    "        state_dict = torch.load(wts, map_location=lambda storage, loc: storage)['state_dict']\n",
    "        for k,v in state_dict.items():\n",
    "            swa_state_dict[k] += v\n",
    "    print('')\n",
    "\n",
    "        #----\n",
    "    for k,v in swa_state_dict.items():\n",
    "        swa_state_dict[k] /= 2\n",
    "\n",
    "        \n",
    "    \n",
    "    if not os.path.exists(outDir):\n",
    "        os.makedirs(outDir)\n",
    "        \n",
    "    name = outDir+f\"\\_Avg_fold_{fold}.ckpt\"\n",
    "    torch.save(swa_state_dict, name)\n",
    "\n",
    "    del swa_state_dict,state_dict,;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\0\\epoch=21_valid_loss=0.1313_valid_accuracy=0.8988.ckpt\n",
      "C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\0\\epoch=13_valid_loss=0.3129_valid_accuracy=0.9002.ckpt None\n",
      "\n",
      "C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\1\\epoch=11_valid_loss=0.1244_valid_accuracy=0.9070.ckpt\n",
      "C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\1\\epoch=8_valid_loss=0.3055_valid_accuracy=0.9007.ckpt None\n",
      "\n",
      "C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\2\\epoch=7_valid_loss=0.1304_valid_accuracy=0.8967.ckpt\n",
      "C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\2\\epoch=12_valid_loss=0.3124_valid_accuracy=0.8988.ckpt None\n",
      "\n",
      "C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\3\\epoch=17_valid_loss=0.1344_valid_accuracy=0.8913.ckpt\n",
      "C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\3\\epoch=11_valid_loss=0.3364_valid_accuracy=0.8909.ckpt None\n",
      "\n",
      "C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_sz_576_Mixup_0.3_focalCosinesLoss_timm_newhead\\4\\epoch=13_valid_loss=0.1341_valid_accuracy=0.8946.ckpt\n",
      "C:\\Users\\Kaggle\\Leaf_Classification\\saved_models\\Image 576\\tf_efficientnet_b4_ns_sz_576_Mixup_0.3_TaylorLoss_timm_newhead\\4\\epoch=9_valid_loss=0.3229_valid_accuracy=0.8916.ckpt None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "#     print(fold)\n",
    "    runcustomSWA(fold=fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
